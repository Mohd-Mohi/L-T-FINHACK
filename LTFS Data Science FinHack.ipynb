{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import os\n",
    "import re\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import itertools\n",
    "from sklearn.metrics import *\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\Mohiuddin\\Desktop\\machine learning\\ML\\av-ltfs data hack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_bqCt9Pv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission_24jSKY6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233154, 41)\n",
      "(112392, 40)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[['YEAR.ACCT.AGE', 'MONTH.ACCT.AGE']] = train_data[\"AVERAGE.ACCT.AGE\"].str.split(' ', expand = True)\n",
    "train_data[['CREDIT.HISTORY.YEAR', 'CREDIT.HISTORY.MONTH']] = train_data[\"CREDIT.HISTORY.LENGTH\"].str.split(' ', expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[['YEAR.ACCT.AGE', 'MONTH.ACCT.AGE']] = test_data[\"AVERAGE.ACCT.AGE\"].str.split(' ', expand = True)\n",
    "test_data[['CREDIT.HISTORY.YEAR', 'CREDIT.HISTORY.MONTH']] = test_data[\"CREDIT.HISTORY.LENGTH\"].str.split(' ', expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['YEAR.ACCT.AGE'] = train_data['YEAR.ACCT.AGE'].str.extract(r'(\\d+)', expand=True).astype(int)\n",
    "train_data['MONTH.ACCT.AGE'] = train_data['MONTH.ACCT.AGE'].str.extract(r'(\\d+)', expand=True).astype(int)\n",
    "train_data['CREDIT.HISTORY.YEAR'] = train_data['CREDIT.HISTORY.YEAR'].str.extract(r'(\\d+)', expand=True).astype(int)\n",
    "train_data['CREDIT.HISTORY.MONTH'] = train_data['CREDIT.HISTORY.MONTH'].str.extract(r'(\\d+)', expand=True).astype(int)\n",
    "test_data['YEAR.ACCT.AGE'] = test_data['YEAR.ACCT.AGE'].str.extract(r'(\\d+)', expand=True).astype(int)\n",
    "test_data['MONTH.ACCT.AGE'] = test_data['MONTH.ACCT.AGE'].str.extract(r'(\\d+)', expand=True).astype(int)\n",
    "test_data['CREDIT.HISTORY.YEAR'] = test_data['CREDIT.HISTORY.YEAR'].str.extract(r'(\\d+)', expand=True).astype(int)\n",
    "test_data['CREDIT.HISTORY.MONTH'] = test_data['CREDIT.HISTORY.MONTH'].str.extract(r'(\\d+)', expand=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date.of.Birth         0\n",
       "Employment.Type    3443\n",
       "dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " test_data.isnull().sum(axis = 0)[8:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Self employed    127635\n",
       "Salaried          97858\n",
       "NaN                7661\n",
       "Name: Employment.Type, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Employment.Type\"].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.replace(np.nan, 'UnEmployed', regex=True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.replace(np.nan, 'UnEmployed', regex=True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Date_of_Birth'] = pd.to_datetime(train_data['Date.of.Birth'])\n",
    "test_data['Date_of_Birth'] = pd.to_datetime(test_data['Date.of.Birth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Disbursal_Date'] = pd.to_datetime(train_data['DisbursalDate'])\n",
    "test_data['Disbursal_Date'] = pd.to_datetime(test_data['DisbursalDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>disbursed_amount</th>\n",
       "      <th>asset_cost</th>\n",
       "      <th>ltv</th>\n",
       "      <th>branch_id</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>manufacturer_id</th>\n",
       "      <th>Current_pincode_ID</th>\n",
       "      <th>Date.of.Birth</th>\n",
       "      <th>Employment.Type</th>\n",
       "      <th>...</th>\n",
       "      <th>AVERAGE.ACCT.AGE</th>\n",
       "      <th>CREDIT.HISTORY.LENGTH</th>\n",
       "      <th>NO.OF_INQUIRIES</th>\n",
       "      <th>loan_default</th>\n",
       "      <th>YEAR.ACCT.AGE</th>\n",
       "      <th>MONTH.ACCT.AGE</th>\n",
       "      <th>CREDIT.HISTORY.YEAR</th>\n",
       "      <th>CREDIT.HISTORY.MONTH</th>\n",
       "      <th>Date_of_Birth</th>\n",
       "      <th>Disbursal_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420825</td>\n",
       "      <td>50578</td>\n",
       "      <td>58400</td>\n",
       "      <td>89.55</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1441</td>\n",
       "      <td>01-01-84</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>...</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1984-01-01</td>\n",
       "      <td>2018-03-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>537409</td>\n",
       "      <td>47145</td>\n",
       "      <td>65550</td>\n",
       "      <td>73.23</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1502</td>\n",
       "      <td>31-07-85</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>...</td>\n",
       "      <td>1yrs 11mon</td>\n",
       "      <td>1yrs 11mon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1985-07-31</td>\n",
       "      <td>2018-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>417566</td>\n",
       "      <td>53278</td>\n",
       "      <td>61360</td>\n",
       "      <td>89.63</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1497</td>\n",
       "      <td>24-08-85</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1985-08-24</td>\n",
       "      <td>2018-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>624493</td>\n",
       "      <td>57513</td>\n",
       "      <td>66113</td>\n",
       "      <td>88.48</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1501</td>\n",
       "      <td>30-12-93</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0yrs 8mon</td>\n",
       "      <td>1yrs 3mon</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1993-12-30</td>\n",
       "      <td>2018-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539055</td>\n",
       "      <td>52378</td>\n",
       "      <td>60300</td>\n",
       "      <td>88.39</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1495</td>\n",
       "      <td>09-12-77</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1977-09-12</td>\n",
       "      <td>2018-09-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UniqueID  disbursed_amount  asset_cost    ltv  branch_id  supplier_id  \\\n",
       "0    420825             50578       58400  89.55         67        22807   \n",
       "1    537409             47145       65550  73.23         67        22807   \n",
       "2    417566             53278       61360  89.63         67        22807   \n",
       "3    624493             57513       66113  88.48         67        22807   \n",
       "4    539055             52378       60300  88.39         67        22807   \n",
       "\n",
       "   manufacturer_id  Current_pincode_ID Date.of.Birth Employment.Type  \\\n",
       "0               45                1441      01-01-84        Salaried   \n",
       "1               45                1502      31-07-85   Self employed   \n",
       "2               45                1497      24-08-85   Self employed   \n",
       "3               45                1501      30-12-93   Self employed   \n",
       "4               45                1495      09-12-77   Self employed   \n",
       "\n",
       "        ...       AVERAGE.ACCT.AGE  CREDIT.HISTORY.LENGTH  NO.OF_INQUIRIES  \\\n",
       "0       ...              0yrs 0mon              0yrs 0mon                0   \n",
       "1       ...             1yrs 11mon             1yrs 11mon                0   \n",
       "2       ...              0yrs 0mon              0yrs 0mon                0   \n",
       "3       ...              0yrs 8mon              1yrs 3mon                1   \n",
       "4       ...              0yrs 0mon              0yrs 0mon                1   \n",
       "\n",
       "   loan_default  YEAR.ACCT.AGE  MONTH.ACCT.AGE  CREDIT.HISTORY.YEAR  \\\n",
       "0             0              0               0                    0   \n",
       "1             1              1              11                    1   \n",
       "2             0              0               0                    0   \n",
       "3             1              0               8                    1   \n",
       "4             1              0               0                    0   \n",
       "\n",
       "   CREDIT.HISTORY.MONTH  Date_of_Birth  Disbursal_Date  \n",
       "0                     0     1984-01-01      2018-03-08  \n",
       "1                    11     1985-07-31      2018-09-26  \n",
       "2                     0     1985-08-24      2018-01-08  \n",
       "3                     3     1993-12-30      2018-10-26  \n",
       "4                     0     1977-09-12      2018-09-26  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_color = LabelEncoder()\n",
    "le_make = LabelEncoder()\n",
    "le_color1 = LabelEncoder()\n",
    "le_make1 = LabelEncoder()\n",
    "\n",
    "train_data['PERFORM_CSN_DESC'] = le_color.fit_transform(train_data[\"PERFORM_CNS.SCORE.DESCRIPTION\"])\n",
    "train_data['Employment_Type'] = le_make.fit_transform(train_data[\"Employment.Type\"])\n",
    "test_data['PERFORM_CSN_DESC'] = le_color1.fit_transform(test_data[\"PERFORM_CNS.SCORE.DESCRIPTION\"])\n",
    "test_data['Employment_Type'] = le_make1.fit_transform(test_data[\"Employment.Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one_hot_tr = pd.get_dummies(train_data['Employment.Type'])\n",
    "#one_hot_te = pd.get_dummies(test_data['Employment.Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employment.Type\n",
       "Salaried         19910\n",
       "Self employed    29057\n",
       "UnEmployed        1644\n",
       "Name: loan_default, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('Employment.Type').loan_default.sum(Normalize= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"DOB_Year\"] = train_data.Date_of_Birth.dt.year\n",
    "test_data[\"DOB_Year\"] = test_data.Date_of_Birth.dt.year\n",
    "train_data[\"Disbursal_Year\"] = train_data.Disbursal_Date.dt.year\n",
    "test_data[\"Disbursal_Year\"] = test_data.Disbursal_Date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"age\"] = train_data[\"Disbursal_Year\"]-train_data[\"DOB_Year\"]\n",
    "test_data[\"age\"] = test_data[\"Disbursal_Year\"]-test_data[\"DOB_Year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"Cost\"] = test_data[\"asset_cost\"]-test_data[\"disbursed_amount\"]\n",
    "train_data[\"Cost\"] = train_data[\"asset_cost\"]-train_data[\"disbursed_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"Total_Santioned\"] = test_data[\"PRI.SANCTIONED.AMOUNT\"]+test_data[\"SEC.CURRENT.BALANCE\"]\n",
    "train_data[\"Total_Santioned\"] = train_data[\"PRI.SANCTIONED.AMOUNT\"]+train_data[\"SEC.CURRENT.BALANCE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"Total_Disburbed\"] = test_data[\"PRI.DISBURSED.AMOUNT\"]+test_data[\"SEC.DISBURSED.AMOUNT\"]\n",
    "train_data[\"Total_Disburbed\"] = train_data[\"PRI.DISBURSED.AMOUNT\"]+train_data[\"SEC.DISBURSED.AMOUNT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Total_instalAmt\"] = train_data[\"PRIMARY.INSTAL.AMT\"]+train_data[\"SEC.INSTAL.AMT\"]\n",
    "test_data[\"Total_instalAmt\"] = test_data[\"PRIMARY.INSTAL.AMT\"]+test_data[\"SEC.INSTAL.AMT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112392, 40)\n",
      "(233154, 40)\n"
     ]
    }
   ],
   "source": [
    "test_data.drop(['UniqueID','Employment.Type','AVERAGE.ACCT.AGE','CREDIT.HISTORY.LENGTH',\"Date.of.Birth\",\"branch_id\",\"supplier_id\",\n",
    "                \"manufacturer_id\",\"Current_pincode_ID\",\"DisbursalDate\", \"PERFORM_CNS.SCORE.DESCRIPTION\",\"State_ID\",\n",
    "                \"Employee_code_ID\",\"Date_of_Birth\", \"Disbursal_Date\"], axis=1,inplace = True)\n",
    "target = train_data[\"loan_default\"]\n",
    "train_data.drop(['UniqueID','Employment.Type','AVERAGE.ACCT.AGE','CREDIT.HISTORY.LENGTH','loan_default',\"Date.of.Birth\",\n",
    "                 \"branch_id\",\"supplier_id\",\"manufacturer_id\",\"Current_pincode_ID\",\n",
    "                 \"DisbursalDate\", \"PERFORM_CNS.SCORE.DESCRIPTION\",\"State_ID\",\"Employee_code_ID\",\n",
    "                 \"Date_of_Birth\", \"Disbursal_Date\"], axis=1,inplace = True)\n",
    "\n",
    "print(test_data.shape)\n",
    "print(train_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "train_data = sc.fit_transform(train_data)\n",
    "test_data = sc.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Neural Network\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=40, units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 40))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling Neural Network\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "233154/233154 [==============================] - 26s 110us/step - loss: 0.5289 - acc: 0.7827\n",
      "Epoch 2/100\n",
      "233154/233154 [==============================] - 25s 105us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 3/100\n",
      "233154/233154 [==============================] - 26s 112us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 4/100\n",
      "233154/233154 [==============================] - 29s 125us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 5/100\n",
      "233154/233154 [==============================] - 26s 111us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 6/100\n",
      "233154/233154 [==============================] - 26s 112us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 7/100\n",
      "233154/233154 [==============================] - 26s 111us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 8/100\n",
      "233154/233154 [==============================] - 26s 112us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 9/100\n",
      "233154/233154 [==============================] - 27s 116us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 10/100\n",
      "233154/233154 [==============================] - 28s 121us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 11/100\n",
      "233154/233154 [==============================] - 25s 109us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 12/100\n",
      "233154/233154 [==============================] - 27s 114us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 13/100\n",
      "233154/233154 [==============================] - 27s 114us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 14/100\n",
      "233154/233154 [==============================] - 24s 105us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 15/100\n",
      "233154/233154 [==============================] - 26s 113us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 16/100\n",
      "233154/233154 [==============================] - 27s 114us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 17/100\n",
      "233154/233154 [==============================] - 23s 97us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 18/100\n",
      "233154/233154 [==============================] - 22s 93us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 19/100\n",
      "233154/233154 [==============================] - 20s 87us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 20/100\n",
      "233154/233154 [==============================] - 21s 91us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 21/100\n",
      "233154/233154 [==============================] - 21s 89us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 22/100\n",
      "233154/233154 [==============================] - 23s 99us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 23/100\n",
      "233154/233154 [==============================] - 24s 101us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 24/100\n",
      "233154/233154 [==============================] - 23s 98us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 25/100\n",
      "233154/233154 [==============================] - 20s 86us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 26/100\n",
      "233154/233154 [==============================] - 21s 89us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 27/100\n",
      "233154/233154 [==============================] - 20s 87us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 28/100\n",
      "233154/233154 [==============================] - 21s 89us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 29/100\n",
      "233154/233154 [==============================] - 21s 89us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 30/100\n",
      "233154/233154 [==============================] - 21s 92us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 31/100\n",
      "233154/233154 [==============================] - 23s 100us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 32/100\n",
      "233154/233154 [==============================] - 24s 104us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 33/100\n",
      "233154/233154 [==============================] - 23s 98us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 34/100\n",
      "233154/233154 [==============================] - 22s 94us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 35/100\n",
      "233154/233154 [==============================] - 22s 96us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 36/100\n",
      "233154/233154 [==============================] - 23s 100us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 37/100\n",
      "233154/233154 [==============================] - 22s 94us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 38/100\n",
      "233154/233154 [==============================] - 24s 104us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 39/100\n",
      "233154/233154 [==============================] - 23s 99us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 40/100\n",
      "233154/233154 [==============================] - 23s 101us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 41/100\n",
      "233154/233154 [==============================] - 26s 110us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 42/100\n",
      "233154/233154 [==============================] - 22s 96us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 43/100\n",
      "233154/233154 [==============================] - 23s 100us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 44/100\n",
      "233154/233154 [==============================] - 25s 108us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 45/100\n",
      "233154/233154 [==============================] - 25s 108us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 46/100\n",
      "233154/233154 [==============================] - 24s 103us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 47/100\n",
      "233154/233154 [==============================] - 25s 106us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 48/100\n",
      "233154/233154 [==============================] - 26s 109us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 49/100\n",
      "233154/233154 [==============================] - 26s 112us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 50/100\n",
      "233154/233154 [==============================] - 26s 113us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 51/100\n",
      "233154/233154 [==============================] - 26s 110us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 52/100\n",
      "233154/233154 [==============================] - 24s 105us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 53/100\n",
      "233154/233154 [==============================] - 26s 112us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 54/100\n",
      "233154/233154 [==============================] - 27s 117us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 55/100\n",
      "233154/233154 [==============================] - 26s 112us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 56/100\n",
      "233154/233154 [==============================] - 26s 110us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 57/100\n",
      "233154/233154 [==============================] - 26s 111us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 58/100\n",
      "233154/233154 [==============================] - 25s 109us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 59/100\n",
      "233154/233154 [==============================] - 23s 98us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 60/100\n",
      "233154/233154 [==============================] - 22s 95us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 61/100\n",
      "233154/233154 [==============================] - 22s 96us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 62/100\n",
      "233154/233154 [==============================] - 23s 101us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 63/100\n",
      "233154/233154 [==============================] - 24s 103us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 64/100\n",
      "233154/233154 [==============================] - 28s 120us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 65/100\n",
      "233154/233154 [==============================] - 27s 117us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 66/100\n",
      "233154/233154 [==============================] - 25s 107us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 67/100\n",
      "233154/233154 [==============================] - 25s 109us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 68/100\n",
      "233154/233154 [==============================] - 25s 108us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 69/100\n",
      "233154/233154 [==============================] - 27s 115us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 70/100\n",
      "233154/233154 [==============================] - 28s 118us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 71/100\n",
      "233154/233154 [==============================] - 24s 104us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 72/100\n",
      "233154/233154 [==============================] - 28s 120us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 73/100\n",
      "233154/233154 [==============================] - 27s 116us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 74/100\n",
      "233154/233154 [==============================] - 26s 110us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 75/100\n",
      "233154/233154 [==============================] - 26s 109us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 76/100\n",
      "233154/233154 [==============================] - 25s 109us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 77/100\n",
      "233154/233154 [==============================] - 26s 111us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233154/233154 [==============================] - 25s 109us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 79/100\n",
      "233154/233154 [==============================] - 25s 108us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 80/100\n",
      "233154/233154 [==============================] - 26s 110us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 81/100\n",
      "233154/233154 [==============================] - 25s 108us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 82/100\n",
      "233154/233154 [==============================] - 26s 110us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 83/100\n",
      "233154/233154 [==============================] - 25s 108us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 84/100\n",
      "233154/233154 [==============================] - 25s 108us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 85/100\n",
      "233154/233154 [==============================] - 24s 103us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 86/100\n",
      "233154/233154 [==============================] - 24s 101us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 87/100\n",
      "233154/233154 [==============================] - 23s 99us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 88/100\n",
      "233154/233154 [==============================] - 24s 101us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 89/100\n",
      "233154/233154 [==============================] - 24s 101us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 90/100\n",
      "233154/233154 [==============================] - 23s 101us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 91/100\n",
      "233154/233154 [==============================] - 25s 109us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 92/100\n",
      "233154/233154 [==============================] - 27s 116us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 93/100\n",
      "233154/233154 [==============================] - 26s 110us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 94/100\n",
      "233154/233154 [==============================] - 25s 108us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 95/100\n",
      "233154/233154 [==============================] - 22s 94us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 96/100\n",
      "233154/233154 [==============================] - 24s 103us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 97/100\n",
      "233154/233154 [==============================] - 24s 103us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 98/100\n",
      "233154/233154 [==============================] - 24s 104us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 99/100\n",
      "233154/233154 [==============================] - 26s 111us/step - loss: 0.5232 - acc: 0.7829\n",
      "Epoch 100/100\n",
      "233154/233154 [==============================] - 24s 102us/step - loss: 0.5232 - acc: 0.7829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e08ca91320>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting our model \n",
    "classifier.fit(train_data, target, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_p = classifier.predict(test_data)\n",
    "\n",
    "y_pred = (y_p > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21992001],\n",
       "       [0.21992001],\n",
       "       [0.21992001],\n",
       "       ...,\n",
       "       [0.21992001],\n",
       "       [0.21992001],\n",
       "       [0.21992001]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(y_pred)\n",
    "x.replace(False, \"0\", regex=True,inplace = True)\n",
    "x.replace(True, \"1\", regex=True,inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"loan_default\"] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"loan_default\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict_proba(test)\n",
    "final_result = pd.DataFrame({'UniqueID':submission['UniqueID'],'loan_default':x})\n",
    "submission.to_csv('88stSolution.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disbursed_amount</th>\n",
       "      <th>asset_cost</th>\n",
       "      <th>ltv</th>\n",
       "      <th>MobileNo_Avl_Flag</th>\n",
       "      <th>Aadhar_flag</th>\n",
       "      <th>PAN_flag</th>\n",
       "      <th>VoterID_flag</th>\n",
       "      <th>Driving_flag</th>\n",
       "      <th>Passport_flag</th>\n",
       "      <th>PERFORM_CNS.SCORE</th>\n",
       "      <th>...</th>\n",
       "      <th>CREDIT.HISTORY.MONTH</th>\n",
       "      <th>PERFORM_CSN_DESC</th>\n",
       "      <th>Employment_Type</th>\n",
       "      <th>DOB_Year</th>\n",
       "      <th>Disbursal_Year</th>\n",
       "      <th>age</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Total_Santioned</th>\n",
       "      <th>Total_Disburbed</th>\n",
       "      <th>Total_instalAmt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50578</td>\n",
       "      <td>58400</td>\n",
       "      <td>89.55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1984</td>\n",
       "      <td>2018</td>\n",
       "      <td>34</td>\n",
       "      <td>7822</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47145</td>\n",
       "      <td>65550</td>\n",
       "      <td>73.23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>598</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1985</td>\n",
       "      <td>2018</td>\n",
       "      <td>33</td>\n",
       "      <td>18405</td>\n",
       "      <td>50200</td>\n",
       "      <td>50200</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53278</td>\n",
       "      <td>61360</td>\n",
       "      <td>89.63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1985</td>\n",
       "      <td>2018</td>\n",
       "      <td>33</td>\n",
       "      <td>8082</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57513</td>\n",
       "      <td>66113</td>\n",
       "      <td>88.48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1993</td>\n",
       "      <td>2018</td>\n",
       "      <td>25</td>\n",
       "      <td>8600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52378</td>\n",
       "      <td>60300</td>\n",
       "      <td>88.39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1977</td>\n",
       "      <td>2018</td>\n",
       "      <td>41</td>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   disbursed_amount  asset_cost    ltv  MobileNo_Avl_Flag  Aadhar_flag  \\\n",
       "0             50578       58400  89.55                  1            1   \n",
       "1             47145       65550  73.23                  1            1   \n",
       "2             53278       61360  89.63                  1            1   \n",
       "3             57513       66113  88.48                  1            1   \n",
       "4             52378       60300  88.39                  1            1   \n",
       "\n",
       "   PAN_flag  VoterID_flag  Driving_flag  Passport_flag  PERFORM_CNS.SCORE  \\\n",
       "0         0             0             0              0                  0   \n",
       "1         0             0             0              0                598   \n",
       "2         0             0             0              0                  0   \n",
       "3         0             0             0              0                305   \n",
       "4         0             0             0              0                  0   \n",
       "\n",
       "        ...         CREDIT.HISTORY.MONTH  PERFORM_CSN_DESC  Employment_Type  \\\n",
       "0       ...                            0                13                0   \n",
       "1       ...                           11                 8                1   \n",
       "2       ...                            0                13                1   \n",
       "3       ...                            3                11                1   \n",
       "4       ...                            0                13                1   \n",
       "\n",
       "   DOB_Year  Disbursal_Year  age   Cost  Total_Santioned  Total_Disburbed  \\\n",
       "0      1984            2018   34   7822                0                0   \n",
       "1      1985            2018   33  18405            50200            50200   \n",
       "2      1985            2018   33   8082                0                0   \n",
       "3      1993            2018   25   8600                0                0   \n",
       "4      1977            2018   41   7922                0                0   \n",
       "\n",
       "   Total_instalAmt  \n",
       "0                0  \n",
       "1             1991  \n",
       "2                0  \n",
       "3               31  \n",
       "4                0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop([\"Date_of_Birth\", \"Disbursal_Date\"], axis=1,inplace = True)\n",
    "test_data.drop([\"Date_of_Birth\", \"Disbursal_Date\"], axis=1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-e715c122d40d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#x_train.drop('target', axis=1, inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#x_train.drop('signal_id', axis=1, inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m param = {'num_leaves': 80,\n\u001b[0;32m      8\u001b[0m          \u001b[1;34m'min_data_in_leaf'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "x_train = train_data\n",
    "target = target\n",
    "input_target = target\n",
    "#x_train.drop('target', axis=1, inplace=True)\n",
    "#x_train.drop('signal_id', axis=1, inplace=True)\n",
    "features = train_data.columns\n",
    "param = {'num_leaves': 80,\n",
    "         'min_data_in_leaf': 60, \n",
    "         'objective':'binary',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.1,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'auc',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"random_state\": 133,\n",
    "         \"verbosity\": -1}\n",
    "max_iter=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold No.1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.735087\tvalid_1's auc: 0.657943\n",
      "[200]\ttraining's auc: 0.782123\tvalid_1's auc: 0.656508\n",
      "Early stopping, best iteration is:\n",
      "[131]\ttraining's auc: 0.751341\tvalid_1's auc: 0.658583\n",
      "Fold No.2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.735731\tvalid_1's auc: 0.658446\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's auc: 0.722998\tvalid_1's auc: 0.658762\n",
      "Fold No.3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.734263\tvalid_1's auc: 0.662024\n",
      "[200]\ttraining's auc: 0.780652\tvalid_1's auc: 0.660857\n",
      "Early stopping, best iteration is:\n",
      "[146]\ttraining's auc: 0.757473\tvalid_1's auc: 0.662301\n",
      "Fold No.4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.734404\tvalid_1's auc: 0.667928\n",
      "[200]\ttraining's auc: 0.780223\tvalid_1's auc: 0.66721\n",
      "Early stopping, best iteration is:\n",
      "[103]\ttraining's auc: 0.735969\tvalid_1's auc: 0.668044\n",
      "Fold No.5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.734412\tvalid_1's auc: 0.66602\n",
      "[200]\ttraining's auc: 0.780492\tvalid_1's auc: 0.664001\n",
      "Early stopping, best iteration is:\n",
      "[101]\ttraining's auc: 0.734914\tvalid_1's auc: 0.666077\n",
      "CV score: 0.66273 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(x_train))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "score = [0 for _ in range(folds.n_splits)]\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train.values, target.values)):\n",
    "    print(\"Fold No.{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(x_train.iloc[trn_idx][features],\n",
    "                           label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(x_train.iloc[val_idx][features],\n",
    "                           label=target.iloc[val_idx])\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds = 100)\n",
    "    \n",
    "    oof[val_idx] = clf.predict(x_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    score[fold_] = metrics.roc_auc_score(target.iloc[val_idx], oof[val_idx])\n",
    "    if fold_ == max_iter - 1: break\n",
    "if (folds.n_splits == max_iter):\n",
    "    print(\"CV score: {:<8.5f}\".format(metrics.roc_auc_score(target, oof)))\n",
    "else:\n",
    "     print(\"CV score: {:<8.5f}\".format(sum(score) / max_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(test_data)\n",
    "predict = pd.Series(predictions).round()\n",
    "predict= predict.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission_24jSKY6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict_proba(test)\n",
    "final_result = pd.DataFrame({'UniqueID':submission['UniqueID'],'loan_default':predict})\n",
    "final_result.to_csv('7stSolution.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    1.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Make the random forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators = 200, random_state = 50, verbose = 1, n_jobs = -1)\n",
    "\n",
    "# Train on the training data\n",
    "random_forest.fit(train_data, target)\n",
    "\n",
    "# Extract feature importances\n",
    "#feature_importance_values = random_forest.feature_importances_\n",
    "#feature_importances = pd.DataFrame({'feature': features, 'importance': feature_importance_values})\n",
    "\n",
    "# Make predictions on the test data\n",
    "prediction = random_forest.predict(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict_proba(test)\n",
    "final_result = pd.DataFrame({'UniqueID':submission['UniqueID'],'loan_default':prediction})\n",
    "final_result.to_csv('12stSolution.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(train_data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission_24jSKY6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict_proba(test)\n",
    "final_result = pd.DataFrame({'UniqueID':submission['UniqueID'],'loan_default':predictions})\n",
    "final_result.to_csv('4stSolution.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1)\n",
    "logreg.fit(train_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logreg.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission_24jSKY6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`#predictions = model.predict_proba(test)\n",
    "final_result = pd.DataFrame({'UniqueID':submission['UniqueID'],'loan_default'folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=59)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=59)\n",
    "predicted = np.zeros((test_data.shape[0]))\n",
    "measured= np.zeros((train_data.shape[0]))\n",
    "score = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-5d6350fb5e0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#model = RandomForestClassifier(n_estimators=500, max_depth=10, min_samples_split=5, n_jobs=-1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mmeasured\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "for times, (trn_idx, val_idx) in enumerate(folds.split(train_data.values,target.values)):\n",
    "    model = RandomForestClassifier(n_estimators=500, n_jobs = -1)\n",
    "    #model = RandomForestClassifier(n_estimators=500, max_depth=10, min_samples_split=5, n_jobs=-1)\n",
    "    model.fit(train_data.iloc[trn_idx],target[trn_idx])\n",
    "    measured[val_idx] = model.predict(train_data.iloc[val_idx])\n",
    "    predicted += model.predict(test_data)/folds.n_splits\n",
    "    score += model.score(train_data.iloc[val_idx],target[val_idx])\n",
    "    print(\"Fold: {} score: {}\".format(times,model.score(train_data.iloc[val_idx],target[val_idx])))\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)\n",
    "    features = train_data.columns\n",
    "    \n",
    "    if model.score(train_data.iloc[val_idx],target[val_idx]) > 0.92000:\n",
    "        hm = 30\n",
    "        plt.figure(figsize=(7, 10))\n",
    "        plt.title('Feature Importances')\n",
    "        plt.barh(range(len(indices[:hm])), importances[indices][:hm], color='b', align='center')\n",
    "        plt.yticks(range(len(indices[:hm])), [features[i] for i in indices])\n",
    "        plt.xlabel('Relative Importance')\n",
    "        plt.show()\n",
    "\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = clf.predict(test_data)\n",
    "predict1 = pd.Series(predicted).round()\n",
    "predict1= predict1.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = pd.DataFrame({'UniqueID':submission['UniqueID'],'loan_default':predict1})\n",
    "final_result.to_csv('11stSolution.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_], axis = 0)\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>disbursed_amount</th>\n",
       "      <td>0.128247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asset_cost</th>\n",
       "      <td>0.132097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ltv</th>\n",
       "      <td>0.134480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MobileNo_Avl_Flag</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aadhar_flag</th>\n",
       "      <td>0.004737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAN_flag</th>\n",
       "      <td>0.007086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VoterID_flag</th>\n",
       "      <td>0.004722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Driving_flag</th>\n",
       "      <td>0.002663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passport_flag</th>\n",
       "      <td>0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERFORM_CNS.SCORE</th>\n",
       "      <td>0.024765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRI.NO.OF.ACCTS</th>\n",
       "      <td>0.015557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRI.ACTIVE.ACCTS</th>\n",
       "      <td>0.008502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRI.OVERDUE.ACCTS</th>\n",
       "      <td>0.005035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRI.CURRENT.BALANCE</th>\n",
       "      <td>0.024178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRI.SANCTIONED.AMOUNT</th>\n",
       "      <td>0.020442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRI.DISBURSED.AMOUNT</th>\n",
       "      <td>0.020432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEC.NO.OF.ACCTS</th>\n",
       "      <td>0.001655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEC.ACTIVE.ACCTS</th>\n",
       "      <td>0.000744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEC.OVERDUE.ACCTS</th>\n",
       "      <td>0.000491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEC.CURRENT.BALANCE</th>\n",
       "      <td>0.001025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       importance\n",
       "disbursed_amount         0.128247\n",
       "asset_cost               0.132097\n",
       "ltv                      0.134480\n",
       "MobileNo_Avl_Flag        0.000000\n",
       "Aadhar_flag              0.004737\n",
       "PAN_flag                 0.007086\n",
       "VoterID_flag             0.004722\n",
       "Driving_flag             0.002663\n",
       "Passport_flag            0.000430\n",
       "PERFORM_CNS.SCORE        0.024765\n",
       "PRI.NO.OF.ACCTS          0.015557\n",
       "PRI.ACTIVE.ACCTS         0.008502\n",
       "PRI.OVERDUE.ACCTS        0.005035\n",
       "PRI.CURRENT.BALANCE      0.024178\n",
       "PRI.SANCTIONED.AMOUNT    0.020442\n",
       "PRI.DISBURSED.AMOUNT     0.020432\n",
       "SEC.NO.OF.ACCTS          0.001655\n",
       "SEC.ACTIVE.ACCTS         0.000744\n",
       "SEC.OVERDUE.ACCTS        0.000491\n",
       "SEC.CURRENT.BALANCE      0.001025"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(importances, index = train_data.columns, columns = ['importance'])\n",
    "feature_importances.sort_values('importance', ascending = False)\n",
    "feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data.drop(columns = ['MobileNo_Avl_Flag', 'Passport_flag', 'SEC.NO.OF.ACCTS',\n",
    "       'SEC.ACTIVE.ACCTS', 'SEC.OVERDUE.ACCTS', 'SEC.CURRENT.BALANCE',\n",
    "       'SEC.SANCTIONED.AMOUNT', 'SEC.DISBURSED.AMOUNT', 'SEC.INSTAL.AMT',\n",
    "       'Disbursal_Year'], axis = 1)\n",
    "test = test_data.drop(columns = ['MobileNo_Avl_Flag', 'Passport_flag', 'SEC.NO.OF.ACCTS',\n",
    "       'SEC.ACTIVE.ACCTS', 'SEC.OVERDUE.ACCTS', 'SEC.CURRENT.BALANCE',\n",
    "       'SEC.SANCTIONED.AMOUNT', 'SEC.DISBURSED.AMOUNT', 'SEC.INSTAL.AMT',\n",
    "       'Disbursal_Year'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data\n",
    "test_data = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numba import jit\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "gc.enable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(train_data.columns.values)\n",
    "X = train_data[features].values\n",
    "y = pd.DataFrame(target).values\n",
    "te = pd.read_csv('test_bqCt9Pv.csv')\n",
    "\n",
    "test = test_data[features].values\n",
    "submission = pd.DataFrame()\n",
    "submission['Unique'] = te.UniqueID.values\n",
    "submission['loan_default'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, validation_X, validation_y, test_X):\n",
    "    param = {}\n",
    "    param['num_class'] = 9\n",
    "    param['objective'] = 'multi:softmax'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['gamma'] = 0\n",
    "    param['eval_metric'] = \"merror\"\n",
    "    param['min_child_weight'] = 3\n",
    "    param['max_delta_step'] = 1\n",
    "    param['subsample'] = 0.9\n",
    "    param['colsample_bytree'] = 0.4\n",
    "    param['colsample_bylevel'] = 0.6\n",
    "    param['colsample_bynode'] = 0.5\n",
    "    param['lambda'] = 0\n",
    "    param['alpha'] = 0\n",
    "    param['seed'] = 0\n",
    "    num_rounds = 500\n",
    "\n",
    "    plst = list(param.items())\n",
    "\n",
    "    xgtrain = xgb.DMatrix(train_X, label = train_y)\n",
    "    xgcv = xgb.DMatrix(validation_X, label = validation_y)\n",
    "    xgtest = xgb.DMatrix(test_X)\n",
    "\n",
    "    evallist = [(xgcv,'eval')]\n",
    "    model = xgb.train(plst, xgtrain, num_rounds, evallist, early_stopping_rounds = 100)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/7]\n",
      "[0]\teval-merror:0.217088\n",
      "Will train until eval-merror hasn't improved in 100 rounds.\n",
      "[1]\teval-merror:0.217088\n",
      "[2]\teval-merror:0.217088\n",
      "[3]\teval-merror:0.217088\n",
      "[4]\teval-merror:0.217088\n",
      "[5]\teval-merror:0.217088\n",
      "[6]\teval-merror:0.217088\n",
      "[7]\teval-merror:0.217088\n",
      "[8]\teval-merror:0.217088\n",
      "[9]\teval-merror:0.217088\n",
      "[10]\teval-merror:0.217088\n",
      "[11]\teval-merror:0.217088\n",
      "[12]\teval-merror:0.217088\n",
      "[13]\teval-merror:0.217088\n",
      "[14]\teval-merror:0.217088\n",
      "[15]\teval-merror:0.217088\n",
      "[16]\teval-merror:0.217088\n",
      "[17]\teval-merror:0.217088\n",
      "[18]\teval-merror:0.217088\n",
      "[19]\teval-merror:0.217088\n",
      "[20]\teval-merror:0.217088\n",
      "[21]\teval-merror:0.217088\n",
      "[22]\teval-merror:0.217088\n",
      "[23]\teval-merror:0.217088\n",
      "[24]\teval-merror:0.217088\n",
      "[25]\teval-merror:0.217088\n",
      "[26]\teval-merror:0.217088\n",
      "[27]\teval-merror:0.217088\n",
      "[28]\teval-merror:0.217088\n",
      "[29]\teval-merror:0.217088\n",
      "[30]\teval-merror:0.217088\n",
      "[31]\teval-merror:0.217088\n",
      "[32]\teval-merror:0.217088\n",
      "[33]\teval-merror:0.217088\n",
      "[34]\teval-merror:0.217119\n",
      "[35]\teval-merror:0.217088\n",
      "[36]\teval-merror:0.217088\n",
      "[37]\teval-merror:0.217088\n",
      "[38]\teval-merror:0.217088\n",
      "[39]\teval-merror:0.217088\n",
      "[40]\teval-merror:0.217058\n",
      "[41]\teval-merror:0.217088\n",
      "[42]\teval-merror:0.217028\n",
      "[43]\teval-merror:0.216998\n",
      "[44]\teval-merror:0.216998\n",
      "[45]\teval-merror:0.216998\n",
      "[46]\teval-merror:0.216998\n",
      "[47]\teval-merror:0.216998\n",
      "[48]\teval-merror:0.217028\n",
      "[49]\teval-merror:0.216998\n",
      "[50]\teval-merror:0.216998\n",
      "[51]\teval-merror:0.217028\n",
      "[52]\teval-merror:0.217058\n",
      "[53]\teval-merror:0.217058\n",
      "[54]\teval-merror:0.217088\n",
      "[55]\teval-merror:0.217058\n",
      "[56]\teval-merror:0.217028\n",
      "[57]\teval-merror:0.216998\n",
      "[58]\teval-merror:0.216938\n",
      "[59]\teval-merror:0.216908\n",
      "[60]\teval-merror:0.216938\n",
      "[61]\teval-merror:0.216938\n",
      "[62]\teval-merror:0.216878\n",
      "[63]\teval-merror:0.216698\n",
      "[64]\teval-merror:0.216668\n",
      "[65]\teval-merror:0.216668\n",
      "[66]\teval-merror:0.216758\n",
      "[67]\teval-merror:0.216668\n",
      "[68]\teval-merror:0.216668\n",
      "[69]\teval-merror:0.216698\n",
      "[70]\teval-merror:0.216638\n",
      "[71]\teval-merror:0.216608\n",
      "[72]\teval-merror:0.216608\n",
      "[73]\teval-merror:0.216608\n",
      "[74]\teval-merror:0.216548\n",
      "[75]\teval-merror:0.216518\n",
      "[76]\teval-merror:0.216488\n",
      "[77]\teval-merror:0.216488\n",
      "[78]\teval-merror:0.216458\n",
      "[79]\teval-merror:0.216458\n",
      "[80]\teval-merror:0.216458\n",
      "[81]\teval-merror:0.216488\n",
      "[82]\teval-merror:0.216488\n",
      "[83]\teval-merror:0.216518\n",
      "[84]\teval-merror:0.216518\n",
      "[85]\teval-merror:0.216488\n",
      "[86]\teval-merror:0.216578\n",
      "[87]\teval-merror:0.216578\n",
      "[88]\teval-merror:0.216518\n",
      "[89]\teval-merror:0.216518\n",
      "[90]\teval-merror:0.216608\n",
      "[91]\teval-merror:0.216548\n",
      "[92]\teval-merror:0.216638\n",
      "[93]\teval-merror:0.216638\n",
      "[94]\teval-merror:0.216608\n",
      "[95]\teval-merror:0.216608\n",
      "[96]\teval-merror:0.216608\n",
      "[97]\teval-merror:0.216578\n",
      "[98]\teval-merror:0.216638\n",
      "[99]\teval-merror:0.216608\n",
      "[100]\teval-merror:0.216578\n",
      "[101]\teval-merror:0.216608\n",
      "[102]\teval-merror:0.216578\n",
      "[103]\teval-merror:0.216608\n",
      "[104]\teval-merror:0.216548\n",
      "[105]\teval-merror:0.216518\n",
      "[106]\teval-merror:0.216548\n",
      "[107]\teval-merror:0.216518\n",
      "[108]\teval-merror:0.216458\n",
      "[109]\teval-merror:0.216458\n",
      "[110]\teval-merror:0.216518\n",
      "[111]\teval-merror:0.216488\n",
      "[112]\teval-merror:0.216548\n",
      "[113]\teval-merror:0.216518\n",
      "[114]\teval-merror:0.216458\n",
      "[115]\teval-merror:0.216428\n",
      "[116]\teval-merror:0.216428\n",
      "[117]\teval-merror:0.216488\n",
      "[118]\teval-merror:0.216488\n",
      "[119]\teval-merror:0.216548\n",
      "[120]\teval-merror:0.216488\n",
      "[121]\teval-merror:0.216488\n",
      "[122]\teval-merror:0.216518\n",
      "[123]\teval-merror:0.216398\n",
      "[124]\teval-merror:0.216368\n",
      "[125]\teval-merror:0.216338\n",
      "[126]\teval-merror:0.216398\n",
      "[127]\teval-merror:0.216458\n",
      "[128]\teval-merror:0.216368\n",
      "[129]\teval-merror:0.216428\n",
      "[130]\teval-merror:0.216488\n",
      "[131]\teval-merror:0.216458\n",
      "[132]\teval-merror:0.216548\n",
      "[133]\teval-merror:0.216578\n",
      "[134]\teval-merror:0.216578\n",
      "[135]\teval-merror:0.216458\n",
      "[136]\teval-merror:0.216458\n",
      "[137]\teval-merror:0.216488\n",
      "[138]\teval-merror:0.216488\n",
      "[139]\teval-merror:0.216428\n",
      "[140]\teval-merror:0.216548\n",
      "[141]\teval-merror:0.216548\n",
      "[142]\teval-merror:0.216548\n",
      "[143]\teval-merror:0.216548\n",
      "[144]\teval-merror:0.216578\n",
      "[145]\teval-merror:0.216608\n",
      "[146]\teval-merror:0.216608\n",
      "[147]\teval-merror:0.216608\n",
      "[148]\teval-merror:0.216578\n",
      "[149]\teval-merror:0.216608\n",
      "[150]\teval-merror:0.216668\n",
      "[151]\teval-merror:0.216608\n",
      "[152]\teval-merror:0.216578\n",
      "[153]\teval-merror:0.216608\n",
      "[154]\teval-merror:0.216548\n",
      "[155]\teval-merror:0.216578\n",
      "[156]\teval-merror:0.216548\n",
      "[157]\teval-merror:0.216518\n",
      "[158]\teval-merror:0.216518\n",
      "[159]\teval-merror:0.216488\n",
      "[160]\teval-merror:0.216428\n",
      "[161]\teval-merror:0.216398\n",
      "[162]\teval-merror:0.216458\n",
      "[163]\teval-merror:0.216428\n",
      "[164]\teval-merror:0.216458\n",
      "[165]\teval-merror:0.216458\n",
      "[166]\teval-merror:0.216458\n",
      "[167]\teval-merror:0.216608\n",
      "[168]\teval-merror:0.216608\n",
      "[169]\teval-merror:0.216548\n",
      "[170]\teval-merror:0.216548\n",
      "[171]\teval-merror:0.216578\n",
      "[172]\teval-merror:0.216608\n",
      "[173]\teval-merror:0.216638\n",
      "[174]\teval-merror:0.216668\n",
      "[175]\teval-merror:0.216668\n",
      "[176]\teval-merror:0.216698\n",
      "[177]\teval-merror:0.216728\n",
      "[178]\teval-merror:0.216698\n",
      "[179]\teval-merror:0.216728\n",
      "[180]\teval-merror:0.216758\n",
      "[181]\teval-merror:0.216788\n",
      "[182]\teval-merror:0.216758\n",
      "[183]\teval-merror:0.216758\n",
      "[184]\teval-merror:0.216848\n",
      "[185]\teval-merror:0.216818\n",
      "[186]\teval-merror:0.216818\n",
      "[187]\teval-merror:0.216758\n",
      "[188]\teval-merror:0.216728\n",
      "[189]\teval-merror:0.216848\n",
      "[190]\teval-merror:0.216818\n",
      "[191]\teval-merror:0.216848\n",
      "[192]\teval-merror:0.216878\n",
      "[193]\teval-merror:0.216908\n",
      "[194]\teval-merror:0.216938\n",
      "[195]\teval-merror:0.216908\n",
      "[196]\teval-merror:0.216908\n",
      "[197]\teval-merror:0.216938\n",
      "[198]\teval-merror:0.216938\n",
      "[199]\teval-merror:0.216908\n",
      "[200]\teval-merror:0.216908\n",
      "[201]\teval-merror:0.216908\n",
      "[202]\teval-merror:0.216938\n",
      "[203]\teval-merror:0.216878\n",
      "[204]\teval-merror:0.216848\n",
      "[205]\teval-merror:0.216788\n",
      "[206]\teval-merror:0.216788\n",
      "[207]\teval-merror:0.216788\n",
      "[208]\teval-merror:0.216788\n",
      "[209]\teval-merror:0.216788\n",
      "[210]\teval-merror:0.216788\n",
      "[211]\teval-merror:0.216758\n",
      "[212]\teval-merror:0.216788\n",
      "[213]\teval-merror:0.216668\n",
      "[214]\teval-merror:0.216668\n",
      "[215]\teval-merror:0.216758\n",
      "[216]\teval-merror:0.216758\n",
      "[217]\teval-merror:0.216698\n",
      "[218]\teval-merror:0.216728\n",
      "[219]\teval-merror:0.216698\n",
      "[220]\teval-merror:0.216698\n",
      "[221]\teval-merror:0.216698\n",
      "[222]\teval-merror:0.216698\n",
      "[223]\teval-merror:0.216698\n",
      "[224]\teval-merror:0.216788\n",
      "[225]\teval-merror:0.216788\n",
      "Stopping. Best iteration:\n",
      "[125]\teval-merror:0.216338\n",
      "\n",
      "[Fold 2/7]\n",
      "[0]\teval-merror:0.217065\n",
      "Will train until eval-merror hasn't improved in 100 rounds.\n",
      "[1]\teval-merror:0.217065\n",
      "[2]\teval-merror:0.217065\n",
      "[3]\teval-merror:0.217065\n",
      "[4]\teval-merror:0.217065\n",
      "[5]\teval-merror:0.217065\n",
      "[6]\teval-merror:0.217065\n",
      "[7]\teval-merror:0.217065\n",
      "[8]\teval-merror:0.217065\n",
      "[9]\teval-merror:0.217065\n",
      "[10]\teval-merror:0.217065\n",
      "[11]\teval-merror:0.217065\n",
      "[12]\teval-merror:0.217065\n",
      "[13]\teval-merror:0.217065\n",
      "[14]\teval-merror:0.217065\n",
      "[15]\teval-merror:0.217065\n",
      "[16]\teval-merror:0.217065\n",
      "[17]\teval-merror:0.217065\n",
      "[18]\teval-merror:0.217065\n",
      "[19]\teval-merror:0.217065\n",
      "[20]\teval-merror:0.217065\n",
      "[21]\teval-merror:0.217065\n",
      "[22]\teval-merror:0.217065\n",
      "[23]\teval-merror:0.217065\n",
      "[24]\teval-merror:0.217065\n",
      "[25]\teval-merror:0.217065\n",
      "[26]\teval-merror:0.217065\n",
      "[27]\teval-merror:0.217065\n",
      "[28]\teval-merror:0.217065\n",
      "[29]\teval-merror:0.217065\n",
      "[30]\teval-merror:0.217065\n",
      "[31]\teval-merror:0.217065\n",
      "[32]\teval-merror:0.217065\n",
      "[33]\teval-merror:0.217035\n",
      "[34]\teval-merror:0.217035\n",
      "[35]\teval-merror:0.217035\n",
      "[36]\teval-merror:0.217035\n",
      "[37]\teval-merror:0.217035\n",
      "[38]\teval-merror:0.217035\n",
      "[39]\teval-merror:0.217035\n",
      "[40]\teval-merror:0.217035\n",
      "[41]\teval-merror:0.217005\n",
      "[42]\teval-merror:0.217005\n",
      "[43]\teval-merror:0.217005\n",
      "[44]\teval-merror:0.217005\n",
      "[45]\teval-merror:0.216975\n",
      "[46]\teval-merror:0.216885\n",
      "[47]\teval-merror:0.216855\n",
      "[48]\teval-merror:0.216825\n",
      "[49]\teval-merror:0.216795\n",
      "[50]\teval-merror:0.216765\n",
      "[51]\teval-merror:0.216705\n",
      "[52]\teval-merror:0.216615\n",
      "[53]\teval-merror:0.216615\n",
      "[54]\teval-merror:0.216585\n",
      "[55]\teval-merror:0.216585\n",
      "[56]\teval-merror:0.216585\n",
      "[57]\teval-merror:0.216495\n",
      "[58]\teval-merror:0.216495\n",
      "[59]\teval-merror:0.216465\n",
      "[60]\teval-merror:0.216434\n",
      "[61]\teval-merror:0.216434\n",
      "[62]\teval-merror:0.216404\n",
      "[63]\teval-merror:0.216434\n",
      "[64]\teval-merror:0.216374\n",
      "[65]\teval-merror:0.216374\n",
      "[66]\teval-merror:0.216434\n",
      "[67]\teval-merror:0.216404\n",
      "[68]\teval-merror:0.216374\n",
      "[69]\teval-merror:0.216374\n",
      "[70]\teval-merror:0.216434\n",
      "[71]\teval-merror:0.216404\n",
      "[72]\teval-merror:0.216404\n",
      "[73]\teval-merror:0.216434\n",
      "[74]\teval-merror:0.216404\n",
      "[75]\teval-merror:0.216495\n",
      "[76]\teval-merror:0.216465\n",
      "[77]\teval-merror:0.216434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78]\teval-merror:0.216465\n",
      "[79]\teval-merror:0.216465\n",
      "[80]\teval-merror:0.216465\n",
      "[81]\teval-merror:0.216404\n",
      "[82]\teval-merror:0.216525\n",
      "[83]\teval-merror:0.216555\n",
      "[84]\teval-merror:0.216555\n",
      "[85]\teval-merror:0.216525\n",
      "[86]\teval-merror:0.216525\n",
      "[87]\teval-merror:0.216555\n",
      "[88]\teval-merror:0.216585\n",
      "[89]\teval-merror:0.216585\n",
      "[90]\teval-merror:0.216645\n",
      "[91]\teval-merror:0.216675\n",
      "[92]\teval-merror:0.216675\n",
      "[93]\teval-merror:0.216705\n",
      "[94]\teval-merror:0.216675\n",
      "[95]\teval-merror:0.216765\n",
      "[96]\teval-merror:0.216615\n",
      "[97]\teval-merror:0.216735\n",
      "[98]\teval-merror:0.216765\n",
      "[99]\teval-merror:0.216585\n",
      "[100]\teval-merror:0.216555\n",
      "[101]\teval-merror:0.216495\n",
      "[102]\teval-merror:0.216585\n",
      "[103]\teval-merror:0.216645\n",
      "[104]\teval-merror:0.216585\n",
      "[105]\teval-merror:0.216705\n",
      "[106]\teval-merror:0.216675\n",
      "[107]\teval-merror:0.216765\n",
      "[108]\teval-merror:0.216765\n",
      "[109]\teval-merror:0.216765\n",
      "[110]\teval-merror:0.216795\n",
      "[111]\teval-merror:0.216765\n",
      "[112]\teval-merror:0.216705\n",
      "[113]\teval-merror:0.216705\n",
      "[114]\teval-merror:0.216675\n",
      "[115]\teval-merror:0.216645\n",
      "[116]\teval-merror:0.216675\n",
      "[117]\teval-merror:0.216705\n",
      "[118]\teval-merror:0.216765\n",
      "[119]\teval-merror:0.216735\n",
      "[120]\teval-merror:0.216705\n",
      "[121]\teval-merror:0.216795\n",
      "[122]\teval-merror:0.216765\n",
      "[123]\teval-merror:0.216765\n",
      "[124]\teval-merror:0.216795\n",
      "[125]\teval-merror:0.216825\n",
      "[126]\teval-merror:0.216855\n",
      "[127]\teval-merror:0.216855\n",
      "[128]\teval-merror:0.216825\n",
      "[129]\teval-merror:0.216855\n",
      "[130]\teval-merror:0.216945\n",
      "[131]\teval-merror:0.216945\n",
      "[132]\teval-merror:0.216945\n",
      "[133]\teval-merror:0.216915\n",
      "[134]\teval-merror:0.216915\n",
      "[135]\teval-merror:0.216915\n",
      "[136]\teval-merror:0.216915\n",
      "[137]\teval-merror:0.216945\n",
      "[138]\teval-merror:0.216945\n",
      "[139]\teval-merror:0.216945\n",
      "[140]\teval-merror:0.216975\n",
      "[141]\teval-merror:0.216975\n",
      "[142]\teval-merror:0.217035\n",
      "[143]\teval-merror:0.217065\n",
      "[144]\teval-merror:0.217035\n",
      "[145]\teval-merror:0.217035\n",
      "[146]\teval-merror:0.217005\n",
      "[147]\teval-merror:0.217035\n",
      "[148]\teval-merror:0.217035\n",
      "[149]\teval-merror:0.217005\n",
      "[150]\teval-merror:0.217005\n",
      "[151]\teval-merror:0.217005\n",
      "[152]\teval-merror:0.216975\n",
      "[153]\teval-merror:0.216945\n",
      "[154]\teval-merror:0.216975\n",
      "[155]\teval-merror:0.216945\n",
      "[156]\teval-merror:0.216945\n",
      "[157]\teval-merror:0.216885\n",
      "[158]\teval-merror:0.216975\n",
      "[159]\teval-merror:0.216975\n",
      "[160]\teval-merror:0.216975\n",
      "[161]\teval-merror:0.216945\n",
      "[162]\teval-merror:0.216975\n",
      "[163]\teval-merror:0.216975\n",
      "[164]\teval-merror:0.216975\n",
      "Stopping. Best iteration:\n",
      "[64]\teval-merror:0.216374\n",
      "\n",
      "[Fold 3/7]\n",
      "[0]\teval-merror:0.217065\n",
      "Will train until eval-merror hasn't improved in 100 rounds.\n",
      "[1]\teval-merror:0.217065\n",
      "[2]\teval-merror:0.217065\n",
      "[3]\teval-merror:0.217065\n",
      "[4]\teval-merror:0.217065\n",
      "[5]\teval-merror:0.217065\n",
      "[6]\teval-merror:0.217065\n",
      "[7]\teval-merror:0.217065\n",
      "[8]\teval-merror:0.217065\n",
      "[9]\teval-merror:0.217065\n",
      "[10]\teval-merror:0.217065\n",
      "[11]\teval-merror:0.217065\n",
      "[12]\teval-merror:0.217065\n",
      "[13]\teval-merror:0.217065\n",
      "[14]\teval-merror:0.217065\n",
      "[15]\teval-merror:0.217065\n",
      "[16]\teval-merror:0.217065\n",
      "[17]\teval-merror:0.217065\n",
      "[18]\teval-merror:0.217065\n",
      "[19]\teval-merror:0.217065\n",
      "[20]\teval-merror:0.217065\n",
      "[21]\teval-merror:0.217065\n",
      "[22]\teval-merror:0.217065\n",
      "[23]\teval-merror:0.217065\n",
      "[24]\teval-merror:0.217065\n",
      "[25]\teval-merror:0.217065\n",
      "[26]\teval-merror:0.217065\n",
      "[27]\teval-merror:0.217065\n",
      "[28]\teval-merror:0.217065\n",
      "[29]\teval-merror:0.217065\n",
      "[30]\teval-merror:0.217065\n",
      "[31]\teval-merror:0.217065\n",
      "[32]\teval-merror:0.217065\n",
      "[33]\teval-merror:0.217095\n",
      "[34]\teval-merror:0.217095\n",
      "[35]\teval-merror:0.217095\n",
      "[36]\teval-merror:0.217035\n",
      "[37]\teval-merror:0.217035\n",
      "[38]\teval-merror:0.217065\n",
      "[39]\teval-merror:0.217065\n",
      "[40]\teval-merror:0.217095\n",
      "[41]\teval-merror:0.217095\n",
      "[42]\teval-merror:0.217065\n",
      "[43]\teval-merror:0.217095\n",
      "[44]\teval-merror:0.217065\n",
      "[45]\teval-merror:0.217035\n",
      "[46]\teval-merror:0.216885\n",
      "[47]\teval-merror:0.216855\n",
      "[48]\teval-merror:0.216855\n",
      "[49]\teval-merror:0.216855\n",
      "[50]\teval-merror:0.216765\n",
      "[51]\teval-merror:0.216765\n",
      "[52]\teval-merror:0.216765\n",
      "[53]\teval-merror:0.216795\n",
      "[54]\teval-merror:0.216705\n",
      "[55]\teval-merror:0.216705\n",
      "[56]\teval-merror:0.216765\n",
      "[57]\teval-merror:0.216765\n",
      "[58]\teval-merror:0.216795\n",
      "[59]\teval-merror:0.216825\n",
      "[60]\teval-merror:0.216735\n",
      "[61]\teval-merror:0.216765\n",
      "[62]\teval-merror:0.216735\n",
      "[63]\teval-merror:0.216735\n",
      "[64]\teval-merror:0.216705\n",
      "[65]\teval-merror:0.216705\n",
      "[66]\teval-merror:0.216705\n",
      "[67]\teval-merror:0.216615\n",
      "[68]\teval-merror:0.216404\n",
      "[69]\teval-merror:0.216404\n",
      "[70]\teval-merror:0.216434\n",
      "[71]\teval-merror:0.216585\n",
      "[72]\teval-merror:0.216585\n",
      "[73]\teval-merror:0.216585\n",
      "[74]\teval-merror:0.216555\n",
      "[75]\teval-merror:0.216615\n",
      "[76]\teval-merror:0.216585\n",
      "[77]\teval-merror:0.216555\n",
      "[78]\teval-merror:0.216404\n",
      "[79]\teval-merror:0.216404\n",
      "[80]\teval-merror:0.216374\n",
      "[81]\teval-merror:0.216374\n",
      "[82]\teval-merror:0.216374\n",
      "[83]\teval-merror:0.216344\n",
      "[84]\teval-merror:0.216404\n",
      "[85]\teval-merror:0.216434\n",
      "[86]\teval-merror:0.216434\n",
      "[87]\teval-merror:0.216434\n",
      "[88]\teval-merror:0.216434\n",
      "[89]\teval-merror:0.216404\n",
      "[90]\teval-merror:0.216434\n",
      "[91]\teval-merror:0.216344\n",
      "[92]\teval-merror:0.216314\n",
      "[93]\teval-merror:0.216284\n",
      "[94]\teval-merror:0.216254\n",
      "[95]\teval-merror:0.216254\n",
      "[96]\teval-merror:0.216224\n",
      "[97]\teval-merror:0.216224\n",
      "[98]\teval-merror:0.216254\n",
      "[99]\teval-merror:0.216284\n",
      "[100]\teval-merror:0.216224\n",
      "[101]\teval-merror:0.216194\n",
      "[102]\teval-merror:0.216284\n",
      "[103]\teval-merror:0.216344\n",
      "[104]\teval-merror:0.216284\n",
      "[105]\teval-merror:0.216284\n",
      "[106]\teval-merror:0.216284\n",
      "[107]\teval-merror:0.216314\n",
      "[108]\teval-merror:0.216314\n",
      "[109]\teval-merror:0.216254\n",
      "[110]\teval-merror:0.216284\n",
      "[111]\teval-merror:0.216314\n",
      "[112]\teval-merror:0.216284\n",
      "[113]\teval-merror:0.216284\n",
      "[114]\teval-merror:0.216314\n",
      "[115]\teval-merror:0.216344\n",
      "[116]\teval-merror:0.216314\n",
      "[117]\teval-merror:0.216284\n",
      "[118]\teval-merror:0.216284\n",
      "[119]\teval-merror:0.216284\n",
      "[120]\teval-merror:0.216284\n",
      "[121]\teval-merror:0.216284\n",
      "[122]\teval-merror:0.216254\n",
      "[123]\teval-merror:0.216224\n",
      "[124]\teval-merror:0.216224\n",
      "[125]\teval-merror:0.216194\n",
      "[126]\teval-merror:0.216194\n",
      "[127]\teval-merror:0.216224\n",
      "[128]\teval-merror:0.216224\n",
      "[129]\teval-merror:0.216164\n",
      "[130]\teval-merror:0.216194\n",
      "[131]\teval-merror:0.216194\n",
      "[132]\teval-merror:0.216224\n",
      "[133]\teval-merror:0.216254\n",
      "[134]\teval-merror:0.216254\n",
      "[135]\teval-merror:0.216254\n",
      "[136]\teval-merror:0.216194\n",
      "[137]\teval-merror:0.216224\n",
      "[138]\teval-merror:0.216254\n",
      "[139]\teval-merror:0.216254\n",
      "[140]\teval-merror:0.216254\n",
      "[141]\teval-merror:0.216284\n",
      "[142]\teval-merror:0.216284\n",
      "[143]\teval-merror:0.216254\n",
      "[144]\teval-merror:0.216284\n",
      "[145]\teval-merror:0.216284\n",
      "[146]\teval-merror:0.216224\n",
      "[147]\teval-merror:0.216284\n",
      "[148]\teval-merror:0.216344\n",
      "[149]\teval-merror:0.216344\n",
      "[150]\teval-merror:0.216344\n",
      "[151]\teval-merror:0.216344\n",
      "[152]\teval-merror:0.216374\n",
      "[153]\teval-merror:0.216254\n",
      "[154]\teval-merror:0.216284\n",
      "[155]\teval-merror:0.216284\n",
      "[156]\teval-merror:0.216314\n",
      "[157]\teval-merror:0.216344\n",
      "[158]\teval-merror:0.216344\n",
      "[159]\teval-merror:0.216344\n",
      "[160]\teval-merror:0.216374\n",
      "[161]\teval-merror:0.216374\n",
      "[162]\teval-merror:0.216404\n",
      "[163]\teval-merror:0.216344\n",
      "[164]\teval-merror:0.216374\n",
      "[165]\teval-merror:0.216404\n",
      "[166]\teval-merror:0.216404\n",
      "[167]\teval-merror:0.216404\n",
      "[168]\teval-merror:0.216404\n",
      "[169]\teval-merror:0.216344\n",
      "[170]\teval-merror:0.216404\n",
      "[171]\teval-merror:0.216344\n",
      "[172]\teval-merror:0.216374\n",
      "[173]\teval-merror:0.216314\n",
      "[174]\teval-merror:0.216254\n",
      "[175]\teval-merror:0.216194\n",
      "[176]\teval-merror:0.216194\n",
      "[177]\teval-merror:0.216194\n",
      "[178]\teval-merror:0.216134\n",
      "[179]\teval-merror:0.216104\n",
      "[180]\teval-merror:0.216104\n",
      "[181]\teval-merror:0.216134\n",
      "[182]\teval-merror:0.216104\n",
      "[183]\teval-merror:0.216134\n",
      "[184]\teval-merror:0.216134\n",
      "[185]\teval-merror:0.216104\n",
      "[186]\teval-merror:0.216164\n",
      "[187]\teval-merror:0.216134\n",
      "[188]\teval-merror:0.216224\n",
      "[189]\teval-merror:0.216194\n",
      "[190]\teval-merror:0.216194\n",
      "[191]\teval-merror:0.216164\n",
      "[192]\teval-merror:0.216194\n",
      "[193]\teval-merror:0.216254\n",
      "[194]\teval-merror:0.216224\n",
      "[195]\teval-merror:0.216254\n",
      "[196]\teval-merror:0.216284\n",
      "[197]\teval-merror:0.216284\n",
      "[198]\teval-merror:0.216254\n",
      "[199]\teval-merror:0.216284\n",
      "[200]\teval-merror:0.216284\n",
      "[201]\teval-merror:0.216284\n",
      "[202]\teval-merror:0.216254\n",
      "[203]\teval-merror:0.216224\n",
      "[204]\teval-merror:0.216254\n",
      "[205]\teval-merror:0.216254\n",
      "[206]\teval-merror:0.216254\n",
      "[207]\teval-merror:0.216254\n",
      "[208]\teval-merror:0.216254\n",
      "[209]\teval-merror:0.216254\n",
      "[210]\teval-merror:0.216254\n",
      "[211]\teval-merror:0.216254\n",
      "[212]\teval-merror:0.216224\n",
      "[213]\teval-merror:0.216224\n",
      "[214]\teval-merror:0.216254\n",
      "[215]\teval-merror:0.216224\n",
      "[216]\teval-merror:0.216164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[217]\teval-merror:0.216194\n",
      "[218]\teval-merror:0.216224\n",
      "[219]\teval-merror:0.216134\n",
      "[220]\teval-merror:0.216164\n",
      "[221]\teval-merror:0.216134\n",
      "[222]\teval-merror:0.216164\n",
      "[223]\teval-merror:0.216134\n",
      "[224]\teval-merror:0.216134\n",
      "[225]\teval-merror:0.216134\n",
      "[226]\teval-merror:0.216134\n",
      "[227]\teval-merror:0.216134\n",
      "[228]\teval-merror:0.216164\n",
      "[229]\teval-merror:0.216134\n",
      "[230]\teval-merror:0.216194\n",
      "[231]\teval-merror:0.216164\n",
      "[232]\teval-merror:0.216164\n",
      "[233]\teval-merror:0.216224\n",
      "[234]\teval-merror:0.216254\n",
      "[235]\teval-merror:0.216284\n",
      "[236]\teval-merror:0.216314\n",
      "[237]\teval-merror:0.216374\n",
      "[238]\teval-merror:0.216404\n",
      "[239]\teval-merror:0.216404\n",
      "[240]\teval-merror:0.216404\n",
      "[241]\teval-merror:0.216374\n",
      "[242]\teval-merror:0.216344\n",
      "[243]\teval-merror:0.216374\n",
      "[244]\teval-merror:0.216374\n",
      "[245]\teval-merror:0.216344\n",
      "[246]\teval-merror:0.216314\n",
      "[247]\teval-merror:0.216344\n",
      "[248]\teval-merror:0.216314\n",
      "[249]\teval-merror:0.216344\n",
      "[250]\teval-merror:0.216344\n",
      "[251]\teval-merror:0.216344\n",
      "[252]\teval-merror:0.216344\n",
      "[253]\teval-merror:0.216374\n",
      "[254]\teval-merror:0.216465\n",
      "[255]\teval-merror:0.216434\n",
      "[256]\teval-merror:0.216495\n",
      "[257]\teval-merror:0.216495\n",
      "[258]\teval-merror:0.216525\n",
      "[259]\teval-merror:0.216495\n",
      "[260]\teval-merror:0.216495\n",
      "[261]\teval-merror:0.216465\n",
      "[262]\teval-merror:0.216434\n",
      "[263]\teval-merror:0.216434\n",
      "[264]\teval-merror:0.216525\n",
      "[265]\teval-merror:0.216495\n",
      "[266]\teval-merror:0.216525\n",
      "[267]\teval-merror:0.216555\n",
      "[268]\teval-merror:0.216555\n",
      "[269]\teval-merror:0.216525\n",
      "[270]\teval-merror:0.216585\n",
      "[271]\teval-merror:0.216555\n",
      "[272]\teval-merror:0.216495\n",
      "[273]\teval-merror:0.216585\n",
      "[274]\teval-merror:0.216555\n",
      "[275]\teval-merror:0.216555\n",
      "[276]\teval-merror:0.216585\n",
      "[277]\teval-merror:0.216585\n",
      "[278]\teval-merror:0.216525\n",
      "[279]\teval-merror:0.216555\n",
      "Stopping. Best iteration:\n",
      "[179]\teval-merror:0.216104\n",
      "\n",
      "[Fold 4/7]\n",
      "[0]\teval-merror:0.217065\n",
      "Will train until eval-merror hasn't improved in 100 rounds.\n",
      "[1]\teval-merror:0.217065\n",
      "[2]\teval-merror:0.217065\n",
      "[3]\teval-merror:0.217065\n",
      "[4]\teval-merror:0.217065\n",
      "[5]\teval-merror:0.217065\n",
      "[6]\teval-merror:0.217065\n",
      "[7]\teval-merror:0.217065\n",
      "[8]\teval-merror:0.217065\n",
      "[9]\teval-merror:0.217065\n",
      "[10]\teval-merror:0.217065\n",
      "[11]\teval-merror:0.217065\n",
      "[12]\teval-merror:0.217065\n",
      "[13]\teval-merror:0.217065\n",
      "[14]\teval-merror:0.217065\n",
      "[15]\teval-merror:0.217065\n",
      "[16]\teval-merror:0.217065\n",
      "[17]\teval-merror:0.217065\n",
      "[18]\teval-merror:0.217065\n",
      "[19]\teval-merror:0.217065\n",
      "[20]\teval-merror:0.217065\n",
      "[21]\teval-merror:0.217065\n",
      "[22]\teval-merror:0.217065\n",
      "[23]\teval-merror:0.217065\n",
      "[24]\teval-merror:0.217065\n",
      "[25]\teval-merror:0.217065\n",
      "[26]\teval-merror:0.217065\n",
      "[27]\teval-merror:0.217065\n",
      "[28]\teval-merror:0.217065\n",
      "[29]\teval-merror:0.217065\n",
      "[30]\teval-merror:0.217065\n",
      "[31]\teval-merror:0.217065\n",
      "[32]\teval-merror:0.217065\n",
      "[33]\teval-merror:0.217065\n",
      "[34]\teval-merror:0.217065\n",
      "[35]\teval-merror:0.217095\n",
      "[36]\teval-merror:0.217095\n",
      "[37]\teval-merror:0.217095\n",
      "[38]\teval-merror:0.217125\n",
      "[39]\teval-merror:0.217125\n",
      "[40]\teval-merror:0.217125\n",
      "[41]\teval-merror:0.217125\n",
      "[42]\teval-merror:0.217125\n",
      "[43]\teval-merror:0.217125\n",
      "[44]\teval-merror:0.217125\n",
      "[45]\teval-merror:0.217125\n",
      "[46]\teval-merror:0.217065\n",
      "[47]\teval-merror:0.217005\n",
      "[48]\teval-merror:0.217005\n",
      "[49]\teval-merror:0.216975\n",
      "[50]\teval-merror:0.216975\n",
      "[51]\teval-merror:0.216945\n",
      "[52]\teval-merror:0.216885\n",
      "[53]\teval-merror:0.216825\n",
      "[54]\teval-merror:0.216795\n",
      "[55]\teval-merror:0.216705\n",
      "[56]\teval-merror:0.216675\n",
      "[57]\teval-merror:0.216645\n",
      "[58]\teval-merror:0.216615\n",
      "[59]\teval-merror:0.216585\n",
      "[60]\teval-merror:0.216525\n",
      "[61]\teval-merror:0.216495\n",
      "[62]\teval-merror:0.216555\n",
      "[63]\teval-merror:0.216495\n",
      "[64]\teval-merror:0.216465\n",
      "[65]\teval-merror:0.216374\n",
      "[66]\teval-merror:0.216404\n",
      "[67]\teval-merror:0.216404\n",
      "[68]\teval-merror:0.216374\n",
      "[69]\teval-merror:0.216434\n",
      "[70]\teval-merror:0.216344\n",
      "[71]\teval-merror:0.216344\n",
      "[72]\teval-merror:0.216284\n",
      "[73]\teval-merror:0.216284\n",
      "[74]\teval-merror:0.216224\n",
      "[75]\teval-merror:0.216224\n",
      "[76]\teval-merror:0.216254\n",
      "[77]\teval-merror:0.216224\n",
      "[78]\teval-merror:0.216194\n",
      "[79]\teval-merror:0.216254\n",
      "[80]\teval-merror:0.216314\n",
      "[81]\teval-merror:0.216465\n",
      "[82]\teval-merror:0.216434\n",
      "[83]\teval-merror:0.216374\n",
      "[84]\teval-merror:0.216434\n",
      "[85]\teval-merror:0.216344\n",
      "[86]\teval-merror:0.216374\n",
      "[87]\teval-merror:0.216374\n",
      "[88]\teval-merror:0.216404\n",
      "[89]\teval-merror:0.216344\n",
      "[90]\teval-merror:0.216374\n",
      "[91]\teval-merror:0.216374\n",
      "[92]\teval-merror:0.216344\n",
      "[93]\teval-merror:0.216314\n",
      "[94]\teval-merror:0.216314\n",
      "[95]\teval-merror:0.216314\n",
      "[96]\teval-merror:0.216284\n",
      "[97]\teval-merror:0.216314\n",
      "[98]\teval-merror:0.216254\n",
      "[99]\teval-merror:0.216194\n",
      "[100]\teval-merror:0.216224\n",
      "[101]\teval-merror:0.216194\n",
      "[102]\teval-merror:0.216134\n",
      "[103]\teval-merror:0.216074\n",
      "[104]\teval-merror:0.216134\n",
      "[105]\teval-merror:0.216104\n",
      "[106]\teval-merror:0.216164\n",
      "[107]\teval-merror:0.216224\n",
      "[108]\teval-merror:0.216164\n",
      "[109]\teval-merror:0.216104\n",
      "[110]\teval-merror:0.216044\n",
      "[111]\teval-merror:0.216074\n",
      "[112]\teval-merror:0.216104\n",
      "[113]\teval-merror:0.216044\n",
      "[114]\teval-merror:0.216164\n",
      "[115]\teval-merror:0.216164\n",
      "[116]\teval-merror:0.216014\n",
      "[117]\teval-merror:0.216134\n",
      "[118]\teval-merror:0.216104\n",
      "[119]\teval-merror:0.216104\n",
      "[120]\teval-merror:0.216014\n",
      "[121]\teval-merror:0.216014\n",
      "[122]\teval-merror:0.216044\n",
      "[123]\teval-merror:0.216044\n",
      "[124]\teval-merror:0.216044\n",
      "[125]\teval-merror:0.216044\n",
      "[126]\teval-merror:0.215984\n",
      "[127]\teval-merror:0.215924\n",
      "[128]\teval-merror:0.215954\n",
      "[129]\teval-merror:0.215924\n",
      "[130]\teval-merror:0.215984\n",
      "[131]\teval-merror:0.215984\n",
      "[132]\teval-merror:0.215954\n",
      "[133]\teval-merror:0.216014\n",
      "[134]\teval-merror:0.216014\n",
      "[135]\teval-merror:0.215954\n",
      "[136]\teval-merror:0.215984\n",
      "[137]\teval-merror:0.216014\n",
      "[138]\teval-merror:0.215924\n",
      "[139]\teval-merror:0.215924\n",
      "[140]\teval-merror:0.216014\n",
      "[141]\teval-merror:0.216074\n",
      "[142]\teval-merror:0.216104\n",
      "[143]\teval-merror:0.216104\n",
      "[144]\teval-merror:0.216134\n",
      "[145]\teval-merror:0.216164\n",
      "[146]\teval-merror:0.216164\n",
      "[147]\teval-merror:0.216164\n",
      "[148]\teval-merror:0.216134\n",
      "[149]\teval-merror:0.216104\n",
      "[150]\teval-merror:0.216104\n",
      "[151]\teval-merror:0.216044\n",
      "[152]\teval-merror:0.216104\n",
      "[153]\teval-merror:0.216104\n",
      "[154]\teval-merror:0.216014\n",
      "[155]\teval-merror:0.216104\n",
      "[156]\teval-merror:0.216074\n",
      "[157]\teval-merror:0.216074\n",
      "[158]\teval-merror:0.216044\n",
      "[159]\teval-merror:0.216074\n",
      "[160]\teval-merror:0.216074\n",
      "[161]\teval-merror:0.216044\n",
      "[162]\teval-merror:0.216044\n",
      "[163]\teval-merror:0.215984\n",
      "[164]\teval-merror:0.216074\n",
      "[165]\teval-merror:0.215954\n",
      "[166]\teval-merror:0.215984\n",
      "[167]\teval-merror:0.216074\n",
      "[168]\teval-merror:0.216134\n",
      "[169]\teval-merror:0.216104\n",
      "[170]\teval-merror:0.216104\n",
      "[171]\teval-merror:0.216134\n",
      "[172]\teval-merror:0.216164\n",
      "[173]\teval-merror:0.216164\n",
      "[174]\teval-merror:0.216134\n",
      "[175]\teval-merror:0.216104\n",
      "[176]\teval-merror:0.216134\n",
      "[177]\teval-merror:0.216164\n",
      "[178]\teval-merror:0.216134\n",
      "[179]\teval-merror:0.216074\n",
      "[180]\teval-merror:0.216074\n",
      "[181]\teval-merror:0.216044\n",
      "[182]\teval-merror:0.216074\n",
      "[183]\teval-merror:0.216044\n",
      "[184]\teval-merror:0.216044\n",
      "[185]\teval-merror:0.216044\n",
      "[186]\teval-merror:0.216014\n",
      "[187]\teval-merror:0.216134\n",
      "[188]\teval-merror:0.216194\n",
      "[189]\teval-merror:0.216164\n",
      "[190]\teval-merror:0.216254\n",
      "[191]\teval-merror:0.216224\n",
      "[192]\teval-merror:0.216164\n",
      "[193]\teval-merror:0.216164\n",
      "[194]\teval-merror:0.216074\n",
      "[195]\teval-merror:0.216164\n",
      "[196]\teval-merror:0.216164\n",
      "[197]\teval-merror:0.216194\n",
      "[198]\teval-merror:0.216164\n",
      "[199]\teval-merror:0.216164\n",
      "[200]\teval-merror:0.216194\n",
      "[201]\teval-merror:0.216134\n",
      "[202]\teval-merror:0.216134\n",
      "[203]\teval-merror:0.216134\n",
      "[204]\teval-merror:0.216074\n",
      "[205]\teval-merror:0.216044\n",
      "[206]\teval-merror:0.216044\n",
      "[207]\teval-merror:0.216074\n",
      "[208]\teval-merror:0.216044\n",
      "[209]\teval-merror:0.216074\n",
      "[210]\teval-merror:0.216074\n",
      "[211]\teval-merror:0.216104\n",
      "[212]\teval-merror:0.216134\n",
      "[213]\teval-merror:0.216134\n",
      "[214]\teval-merror:0.216074\n",
      "[215]\teval-merror:0.216104\n",
      "[216]\teval-merror:0.216044\n",
      "[217]\teval-merror:0.216044\n",
      "[218]\teval-merror:0.216074\n",
      "[219]\teval-merror:0.216074\n",
      "[220]\teval-merror:0.216104\n",
      "[221]\teval-merror:0.216134\n",
      "[222]\teval-merror:0.216044\n",
      "[223]\teval-merror:0.216104\n",
      "[224]\teval-merror:0.216104\n",
      "[225]\teval-merror:0.216074\n",
      "[226]\teval-merror:0.216074\n",
      "[227]\teval-merror:0.216104\n",
      "Stopping. Best iteration:\n",
      "[127]\teval-merror:0.215924\n",
      "\n",
      "[Fold 5/7]\n",
      "[0]\teval-merror:0.217071\n",
      "Will train until eval-merror hasn't improved in 100 rounds.\n",
      "[1]\teval-merror:0.217071\n",
      "[2]\teval-merror:0.217071\n",
      "[3]\teval-merror:0.217071\n",
      "[4]\teval-merror:0.217071\n",
      "[5]\teval-merror:0.217071\n",
      "[6]\teval-merror:0.217071\n",
      "[7]\teval-merror:0.217071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\teval-merror:0.217071\n",
      "[9]\teval-merror:0.217071\n",
      "[10]\teval-merror:0.217071\n",
      "[11]\teval-merror:0.217071\n",
      "[12]\teval-merror:0.217071\n",
      "[13]\teval-merror:0.217071\n",
      "[14]\teval-merror:0.217071\n",
      "[15]\teval-merror:0.217071\n",
      "[16]\teval-merror:0.217071\n",
      "[17]\teval-merror:0.217071\n",
      "[18]\teval-merror:0.217071\n",
      "[19]\teval-merror:0.217071\n",
      "[20]\teval-merror:0.217071\n",
      "[21]\teval-merror:0.217071\n",
      "[22]\teval-merror:0.217071\n",
      "[23]\teval-merror:0.217071\n",
      "[24]\teval-merror:0.217071\n",
      "[25]\teval-merror:0.217071\n",
      "[26]\teval-merror:0.217071\n",
      "[27]\teval-merror:0.217071\n",
      "[28]\teval-merror:0.217071\n",
      "[29]\teval-merror:0.217071\n",
      "[30]\teval-merror:0.217071\n",
      "[31]\teval-merror:0.217071\n",
      "[32]\teval-merror:0.217071\n",
      "[33]\teval-merror:0.217071\n",
      "[34]\teval-merror:0.217071\n",
      "[35]\teval-merror:0.217041\n",
      "[36]\teval-merror:0.217011\n",
      "[37]\teval-merror:0.217011\n",
      "[38]\teval-merror:0.217011\n",
      "[39]\teval-merror:0.217011\n",
      "[40]\teval-merror:0.217011\n",
      "[41]\teval-merror:0.217011\n",
      "[42]\teval-merror:0.216981\n",
      "[43]\teval-merror:0.216951\n",
      "[44]\teval-merror:0.216981\n",
      "[45]\teval-merror:0.216981\n",
      "[46]\teval-merror:0.217011\n",
      "[47]\teval-merror:0.216981\n",
      "[48]\teval-merror:0.216951\n",
      "[49]\teval-merror:0.216891\n",
      "[50]\teval-merror:0.216861\n",
      "[51]\teval-merror:0.216801\n",
      "[52]\teval-merror:0.216801\n",
      "[53]\teval-merror:0.216771\n",
      "[54]\teval-merror:0.216801\n",
      "[55]\teval-merror:0.216801\n",
      "[56]\teval-merror:0.216801\n",
      "[57]\teval-merror:0.216741\n",
      "[58]\teval-merror:0.216741\n",
      "[59]\teval-merror:0.216771\n",
      "[60]\teval-merror:0.216771\n",
      "[61]\teval-merror:0.216801\n",
      "[62]\teval-merror:0.216771\n",
      "[63]\teval-merror:0.216711\n",
      "[64]\teval-merror:0.216711\n",
      "[65]\teval-merror:0.216711\n",
      "[66]\teval-merror:0.216741\n",
      "[67]\teval-merror:0.216741\n",
      "[68]\teval-merror:0.216741\n",
      "[69]\teval-merror:0.216711\n",
      "[70]\teval-merror:0.216711\n",
      "[71]\teval-merror:0.216651\n",
      "[72]\teval-merror:0.216621\n",
      "[73]\teval-merror:0.216681\n",
      "[74]\teval-merror:0.216591\n",
      "[75]\teval-merror:0.216591\n",
      "[76]\teval-merror:0.216591\n",
      "[77]\teval-merror:0.216621\n",
      "[78]\teval-merror:0.216591\n",
      "[79]\teval-merror:0.216531\n",
      "[80]\teval-merror:0.216621\n",
      "[81]\teval-merror:0.216561\n",
      "[82]\teval-merror:0.216531\n",
      "[83]\teval-merror:0.216501\n",
      "[84]\teval-merror:0.216471\n",
      "[85]\teval-merror:0.216441\n",
      "[86]\teval-merror:0.216381\n",
      "[87]\teval-merror:0.216471\n",
      "[88]\teval-merror:0.216501\n",
      "[89]\teval-merror:0.216471\n",
      "[90]\teval-merror:0.216501\n",
      "[91]\teval-merror:0.216501\n",
      "[92]\teval-merror:0.216531\n",
      "[93]\teval-merror:0.216531\n",
      "[94]\teval-merror:0.216591\n",
      "[95]\teval-merror:0.216621\n",
      "[96]\teval-merror:0.216621\n",
      "[97]\teval-merror:0.216621\n",
      "[98]\teval-merror:0.216561\n",
      "[99]\teval-merror:0.216531\n",
      "[100]\teval-merror:0.216531\n",
      "[101]\teval-merror:0.216471\n",
      "[102]\teval-merror:0.216441\n",
      "[103]\teval-merror:0.216441\n",
      "[104]\teval-merror:0.216621\n",
      "[105]\teval-merror:0.216651\n",
      "[106]\teval-merror:0.216681\n",
      "[107]\teval-merror:0.216741\n",
      "[108]\teval-merror:0.216741\n",
      "[109]\teval-merror:0.216771\n",
      "[110]\teval-merror:0.216771\n",
      "[111]\teval-merror:0.216681\n",
      "[112]\teval-merror:0.216741\n",
      "[113]\teval-merror:0.216741\n",
      "[114]\teval-merror:0.216711\n",
      "[115]\teval-merror:0.216771\n",
      "[116]\teval-merror:0.216771\n",
      "[117]\teval-merror:0.216741\n",
      "[118]\teval-merror:0.216711\n",
      "[119]\teval-merror:0.216741\n",
      "[120]\teval-merror:0.216741\n",
      "[121]\teval-merror:0.216741\n",
      "[122]\teval-merror:0.216771\n",
      "[123]\teval-merror:0.216711\n",
      "[124]\teval-merror:0.216681\n",
      "[125]\teval-merror:0.216681\n",
      "[126]\teval-merror:0.216681\n",
      "[127]\teval-merror:0.216711\n",
      "[128]\teval-merror:0.216711\n",
      "[129]\teval-merror:0.216711\n",
      "[130]\teval-merror:0.216711\n",
      "[131]\teval-merror:0.216681\n",
      "[132]\teval-merror:0.216651\n",
      "[133]\teval-merror:0.216621\n",
      "[134]\teval-merror:0.216651\n",
      "[135]\teval-merror:0.216681\n",
      "[136]\teval-merror:0.216681\n",
      "[137]\teval-merror:0.216651\n",
      "[138]\teval-merror:0.216681\n",
      "[139]\teval-merror:0.216651\n",
      "[140]\teval-merror:0.216651\n",
      "[141]\teval-merror:0.216651\n",
      "[142]\teval-merror:0.216651\n",
      "[143]\teval-merror:0.216681\n",
      "[144]\teval-merror:0.216741\n",
      "[145]\teval-merror:0.216651\n",
      "[146]\teval-merror:0.216711\n",
      "[147]\teval-merror:0.216681\n",
      "[148]\teval-merror:0.216591\n",
      "[149]\teval-merror:0.216561\n",
      "[150]\teval-merror:0.216591\n",
      "[151]\teval-merror:0.216681\n",
      "[152]\teval-merror:0.216651\n",
      "[153]\teval-merror:0.216681\n",
      "[154]\teval-merror:0.216711\n",
      "[155]\teval-merror:0.216681\n",
      "[156]\teval-merror:0.216681\n",
      "[157]\teval-merror:0.216651\n",
      "[158]\teval-merror:0.216651\n",
      "[159]\teval-merror:0.216651\n",
      "[160]\teval-merror:0.216681\n",
      "[161]\teval-merror:0.216651\n",
      "[162]\teval-merror:0.216591\n",
      "[163]\teval-merror:0.216621\n",
      "[164]\teval-merror:0.216591\n",
      "[165]\teval-merror:0.216531\n",
      "[166]\teval-merror:0.216591\n",
      "[167]\teval-merror:0.216621\n",
      "[168]\teval-merror:0.216651\n",
      "[169]\teval-merror:0.216651\n",
      "[170]\teval-merror:0.216651\n",
      "[171]\teval-merror:0.216651\n",
      "[172]\teval-merror:0.216561\n",
      "[173]\teval-merror:0.216651\n",
      "[174]\teval-merror:0.216651\n",
      "[175]\teval-merror:0.216561\n",
      "[176]\teval-merror:0.216621\n",
      "[177]\teval-merror:0.216561\n",
      "[178]\teval-merror:0.216591\n",
      "[179]\teval-merror:0.216591\n",
      "[180]\teval-merror:0.216591\n",
      "[181]\teval-merror:0.216561\n",
      "[182]\teval-merror:0.216561\n",
      "[183]\teval-merror:0.216621\n",
      "[184]\teval-merror:0.216591\n",
      "[185]\teval-merror:0.216621\n",
      "[186]\teval-merror:0.216501\n",
      "Stopping. Best iteration:\n",
      "[86]\teval-merror:0.216381\n",
      "\n",
      "[Fold 6/7]\n",
      "[0]\teval-merror:0.217071\n",
      "Will train until eval-merror hasn't improved in 100 rounds.\n",
      "[1]\teval-merror:0.217071\n",
      "[2]\teval-merror:0.217071\n",
      "[3]\teval-merror:0.217071\n",
      "[4]\teval-merror:0.217071\n",
      "[5]\teval-merror:0.217071\n",
      "[6]\teval-merror:0.217071\n",
      "[7]\teval-merror:0.217071\n",
      "[8]\teval-merror:0.217071\n",
      "[9]\teval-merror:0.217071\n",
      "[10]\teval-merror:0.217071\n",
      "[11]\teval-merror:0.217071\n",
      "[12]\teval-merror:0.217071\n",
      "[13]\teval-merror:0.217071\n",
      "[14]\teval-merror:0.217071\n",
      "[15]\teval-merror:0.217071\n",
      "[16]\teval-merror:0.217071\n",
      "[17]\teval-merror:0.217071\n",
      "[18]\teval-merror:0.217071\n",
      "[19]\teval-merror:0.217071\n",
      "[20]\teval-merror:0.217071\n",
      "[21]\teval-merror:0.217071\n",
      "[22]\teval-merror:0.217071\n",
      "[23]\teval-merror:0.217071\n",
      "[24]\teval-merror:0.217071\n",
      "[25]\teval-merror:0.217071\n",
      "[26]\teval-merror:0.217071\n",
      "[27]\teval-merror:0.217102\n",
      "[28]\teval-merror:0.217102\n",
      "[29]\teval-merror:0.217102\n",
      "[30]\teval-merror:0.217102\n",
      "[31]\teval-merror:0.217102\n",
      "[32]\teval-merror:0.217102\n",
      "[33]\teval-merror:0.217102\n",
      "[34]\teval-merror:0.217132\n",
      "[35]\teval-merror:0.217132\n",
      "[36]\teval-merror:0.217132\n",
      "[37]\teval-merror:0.217132\n",
      "[38]\teval-merror:0.217102\n",
      "[39]\teval-merror:0.217071\n",
      "[40]\teval-merror:0.217011\n",
      "[41]\teval-merror:0.216981\n",
      "[42]\teval-merror:0.216891\n",
      "[43]\teval-merror:0.216921\n",
      "[44]\teval-merror:0.216861\n",
      "[45]\teval-merror:0.216801\n",
      "[46]\teval-merror:0.216771\n",
      "[47]\teval-merror:0.216711\n",
      "[48]\teval-merror:0.216651\n",
      "[49]\teval-merror:0.216621\n",
      "[50]\teval-merror:0.216711\n",
      "[51]\teval-merror:0.216681\n",
      "[52]\teval-merror:0.216771\n",
      "[53]\teval-merror:0.216771\n",
      "[54]\teval-merror:0.216801\n",
      "[55]\teval-merror:0.216801\n",
      "[56]\teval-merror:0.216771\n",
      "[57]\teval-merror:0.216741\n",
      "[58]\teval-merror:0.216651\n",
      "[59]\teval-merror:0.216591\n",
      "[60]\teval-merror:0.216561\n",
      "[61]\teval-merror:0.216651\n",
      "[62]\teval-merror:0.216531\n",
      "[63]\teval-merror:0.216501\n",
      "[64]\teval-merror:0.216411\n",
      "[65]\teval-merror:0.216381\n",
      "[66]\teval-merror:0.216381\n",
      "[67]\teval-merror:0.216441\n",
      "[68]\teval-merror:0.216441\n",
      "[69]\teval-merror:0.216441\n",
      "[70]\teval-merror:0.216411\n",
      "[71]\teval-merror:0.216471\n",
      "[72]\teval-merror:0.216411\n",
      "[73]\teval-merror:0.216441\n",
      "[74]\teval-merror:0.216471\n",
      "[75]\teval-merror:0.216441\n",
      "[76]\teval-merror:0.216411\n",
      "[77]\teval-merror:0.216381\n",
      "[78]\teval-merror:0.216351\n",
      "[79]\teval-merror:0.216441\n",
      "[80]\teval-merror:0.216411\n",
      "[81]\teval-merror:0.216381\n",
      "[82]\teval-merror:0.216501\n",
      "[83]\teval-merror:0.216531\n",
      "[84]\teval-merror:0.216651\n",
      "[85]\teval-merror:0.216681\n",
      "[86]\teval-merror:0.216771\n",
      "[87]\teval-merror:0.216651\n",
      "[88]\teval-merror:0.216771\n",
      "[89]\teval-merror:0.216801\n",
      "[90]\teval-merror:0.216831\n",
      "[91]\teval-merror:0.216831\n",
      "[92]\teval-merror:0.216951\n",
      "[93]\teval-merror:0.216951\n",
      "[94]\teval-merror:0.216861\n",
      "[95]\teval-merror:0.216741\n",
      "[96]\teval-merror:0.216801\n",
      "[97]\teval-merror:0.216801\n",
      "[98]\teval-merror:0.216741\n",
      "[99]\teval-merror:0.216771\n",
      "[100]\teval-merror:0.216771\n",
      "[101]\teval-merror:0.216801\n",
      "[102]\teval-merror:0.216711\n",
      "[103]\teval-merror:0.216621\n",
      "[104]\teval-merror:0.216621\n",
      "[105]\teval-merror:0.216651\n",
      "[106]\teval-merror:0.216561\n",
      "[107]\teval-merror:0.216651\n",
      "[108]\teval-merror:0.216711\n",
      "[109]\teval-merror:0.216711\n",
      "[110]\teval-merror:0.216711\n",
      "[111]\teval-merror:0.216681\n",
      "[112]\teval-merror:0.216651\n",
      "[113]\teval-merror:0.216591\n",
      "[114]\teval-merror:0.216531\n",
      "[115]\teval-merror:0.216591\n",
      "[116]\teval-merror:0.216651\n",
      "[117]\teval-merror:0.216561\n",
      "[118]\teval-merror:0.216531\n",
      "[119]\teval-merror:0.216561\n",
      "[120]\teval-merror:0.216561\n",
      "[121]\teval-merror:0.216561\n",
      "[122]\teval-merror:0.216501\n",
      "[123]\teval-merror:0.216561\n",
      "[124]\teval-merror:0.216501\n",
      "[125]\teval-merror:0.216501\n",
      "[126]\teval-merror:0.216531\n",
      "[127]\teval-merror:0.216471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128]\teval-merror:0.216471\n",
      "[129]\teval-merror:0.216471\n",
      "[130]\teval-merror:0.216441\n",
      "[131]\teval-merror:0.216441\n",
      "[132]\teval-merror:0.216471\n",
      "[133]\teval-merror:0.216411\n",
      "[134]\teval-merror:0.216411\n",
      "[135]\teval-merror:0.216411\n",
      "[136]\teval-merror:0.216441\n",
      "[137]\teval-merror:0.216471\n",
      "[138]\teval-merror:0.216501\n",
      "[139]\teval-merror:0.216591\n",
      "[140]\teval-merror:0.216501\n",
      "[141]\teval-merror:0.216531\n",
      "[142]\teval-merror:0.216561\n",
      "[143]\teval-merror:0.216561\n",
      "[144]\teval-merror:0.216501\n",
      "[145]\teval-merror:0.216531\n",
      "[146]\teval-merror:0.216531\n",
      "[147]\teval-merror:0.216531\n",
      "[148]\teval-merror:0.216501\n",
      "[149]\teval-merror:0.216531\n",
      "[150]\teval-merror:0.216561\n",
      "[151]\teval-merror:0.216531\n",
      "[152]\teval-merror:0.216561\n",
      "[153]\teval-merror:0.216531\n",
      "[154]\teval-merror:0.216531\n",
      "[155]\teval-merror:0.216531\n",
      "[156]\teval-merror:0.216561\n",
      "[157]\teval-merror:0.216531\n",
      "[158]\teval-merror:0.216501\n",
      "[159]\teval-merror:0.216531\n",
      "[160]\teval-merror:0.216531\n",
      "[161]\teval-merror:0.216531\n",
      "[162]\teval-merror:0.216621\n",
      "[163]\teval-merror:0.216591\n",
      "[164]\teval-merror:0.216621\n",
      "[165]\teval-merror:0.216621\n",
      "[166]\teval-merror:0.216651\n",
      "[167]\teval-merror:0.216681\n",
      "[168]\teval-merror:0.216651\n",
      "[169]\teval-merror:0.216651\n",
      "[170]\teval-merror:0.216681\n",
      "[171]\teval-merror:0.216681\n",
      "[172]\teval-merror:0.216741\n",
      "[173]\teval-merror:0.216801\n",
      "[174]\teval-merror:0.216771\n",
      "[175]\teval-merror:0.216741\n",
      "[176]\teval-merror:0.216711\n",
      "[177]\teval-merror:0.216651\n",
      "[178]\teval-merror:0.216591\n",
      "Stopping. Best iteration:\n",
      "[78]\teval-merror:0.216351\n",
      "\n",
      "[Fold 7/7]\n",
      "[0]\teval-merror:0.217071\n",
      "Will train until eval-merror hasn't improved in 100 rounds.\n",
      "[1]\teval-merror:0.217071\n",
      "[2]\teval-merror:0.217071\n",
      "[3]\teval-merror:0.217071\n",
      "[4]\teval-merror:0.217071\n",
      "[5]\teval-merror:0.217071\n",
      "[6]\teval-merror:0.217071\n",
      "[7]\teval-merror:0.217071\n",
      "[8]\teval-merror:0.217071\n",
      "[9]\teval-merror:0.217071\n",
      "[10]\teval-merror:0.217071\n",
      "[11]\teval-merror:0.217071\n",
      "[12]\teval-merror:0.217071\n",
      "[13]\teval-merror:0.217071\n",
      "[14]\teval-merror:0.217071\n",
      "[15]\teval-merror:0.217071\n",
      "[16]\teval-merror:0.217071\n",
      "[17]\teval-merror:0.217071\n",
      "[18]\teval-merror:0.217071\n",
      "[19]\teval-merror:0.217071\n",
      "[20]\teval-merror:0.217071\n",
      "[21]\teval-merror:0.217071\n",
      "[22]\teval-merror:0.217071\n",
      "[23]\teval-merror:0.217071\n",
      "[24]\teval-merror:0.217071\n",
      "[25]\teval-merror:0.217071\n",
      "[26]\teval-merror:0.217071\n",
      "[27]\teval-merror:0.217071\n",
      "[28]\teval-merror:0.217071\n",
      "[29]\teval-merror:0.217071\n",
      "[30]\teval-merror:0.217071\n",
      "[31]\teval-merror:0.217071\n",
      "[32]\teval-merror:0.217071\n",
      "[33]\teval-merror:0.217071\n",
      "[34]\teval-merror:0.217071\n",
      "[35]\teval-merror:0.217071\n",
      "[36]\teval-merror:0.217071\n",
      "[37]\teval-merror:0.217071\n",
      "[38]\teval-merror:0.217041\n",
      "[39]\teval-merror:0.217011\n",
      "[40]\teval-merror:0.217011\n",
      "[41]\teval-merror:0.217011\n",
      "[42]\teval-merror:0.216921\n",
      "[43]\teval-merror:0.216891\n",
      "[44]\teval-merror:0.216861\n",
      "[45]\teval-merror:0.216831\n",
      "[46]\teval-merror:0.216831\n",
      "[47]\teval-merror:0.216771\n",
      "[48]\teval-merror:0.216741\n",
      "[49]\teval-merror:0.216741\n",
      "[50]\teval-merror:0.216741\n",
      "[51]\teval-merror:0.216711\n",
      "[52]\teval-merror:0.216651\n",
      "[53]\teval-merror:0.216651\n",
      "[54]\teval-merror:0.216681\n",
      "[55]\teval-merror:0.216741\n",
      "[56]\teval-merror:0.216771\n",
      "[57]\teval-merror:0.216771\n",
      "[58]\teval-merror:0.216681\n",
      "[59]\teval-merror:0.216711\n",
      "[60]\teval-merror:0.216711\n",
      "[61]\teval-merror:0.216771\n",
      "[62]\teval-merror:0.216771\n",
      "[63]\teval-merror:0.216831\n",
      "[64]\teval-merror:0.216741\n",
      "[65]\teval-merror:0.216771\n",
      "[66]\teval-merror:0.216771\n",
      "[67]\teval-merror:0.216861\n",
      "[68]\teval-merror:0.216831\n",
      "[69]\teval-merror:0.216831\n",
      "[70]\teval-merror:0.216831\n",
      "[71]\teval-merror:0.216741\n",
      "[72]\teval-merror:0.216681\n",
      "[73]\teval-merror:0.216621\n",
      "[74]\teval-merror:0.216651\n",
      "[75]\teval-merror:0.216651\n",
      "[76]\teval-merror:0.216651\n",
      "[77]\teval-merror:0.216741\n",
      "[78]\teval-merror:0.216771\n",
      "[79]\teval-merror:0.216741\n",
      "[80]\teval-merror:0.216741\n",
      "[81]\teval-merror:0.216741\n",
      "[82]\teval-merror:0.216741\n",
      "[83]\teval-merror:0.216741\n",
      "[84]\teval-merror:0.216711\n",
      "[85]\teval-merror:0.216681\n",
      "[86]\teval-merror:0.216741\n",
      "[87]\teval-merror:0.216681\n",
      "[88]\teval-merror:0.216681\n",
      "[89]\teval-merror:0.216621\n",
      "[90]\teval-merror:0.216651\n",
      "[91]\teval-merror:0.216651\n",
      "[92]\teval-merror:0.216681\n",
      "[93]\teval-merror:0.216741\n",
      "[94]\teval-merror:0.216681\n",
      "[95]\teval-merror:0.216711\n",
      "[96]\teval-merror:0.216741\n",
      "[97]\teval-merror:0.216651\n",
      "[98]\teval-merror:0.216651\n",
      "[99]\teval-merror:0.216651\n",
      "[100]\teval-merror:0.216681\n",
      "[101]\teval-merror:0.216681\n",
      "[102]\teval-merror:0.216561\n",
      "[103]\teval-merror:0.216561\n",
      "[104]\teval-merror:0.216561\n",
      "[105]\teval-merror:0.216501\n",
      "[106]\teval-merror:0.216561\n",
      "[107]\teval-merror:0.216441\n",
      "[108]\teval-merror:0.216441\n",
      "[109]\teval-merror:0.216441\n",
      "[110]\teval-merror:0.216471\n",
      "[111]\teval-merror:0.216531\n",
      "[112]\teval-merror:0.216561\n",
      "[113]\teval-merror:0.216531\n",
      "[114]\teval-merror:0.216561\n",
      "[115]\teval-merror:0.216411\n",
      "[116]\teval-merror:0.216321\n",
      "[117]\teval-merror:0.216351\n",
      "[118]\teval-merror:0.216441\n",
      "[119]\teval-merror:0.216471\n",
      "[120]\teval-merror:0.216471\n",
      "[121]\teval-merror:0.216441\n",
      "[122]\teval-merror:0.216441\n",
      "[123]\teval-merror:0.216441\n",
      "[124]\teval-merror:0.216411\n",
      "[125]\teval-merror:0.216381\n",
      "[126]\teval-merror:0.216381\n",
      "[127]\teval-merror:0.216381\n",
      "[128]\teval-merror:0.216381\n",
      "[129]\teval-merror:0.216411\n",
      "[130]\teval-merror:0.216411\n",
      "[131]\teval-merror:0.216351\n",
      "[132]\teval-merror:0.216411\n",
      "[133]\teval-merror:0.216411\n",
      "[134]\teval-merror:0.216501\n",
      "[135]\teval-merror:0.216531\n",
      "[136]\teval-merror:0.216561\n",
      "[137]\teval-merror:0.216621\n",
      "[138]\teval-merror:0.216711\n",
      "[139]\teval-merror:0.216711\n",
      "[140]\teval-merror:0.216741\n",
      "[141]\teval-merror:0.216861\n",
      "[142]\teval-merror:0.216861\n",
      "[143]\teval-merror:0.216831\n",
      "[144]\teval-merror:0.216771\n",
      "[145]\teval-merror:0.216831\n",
      "[146]\teval-merror:0.216801\n",
      "[147]\teval-merror:0.216831\n",
      "[148]\teval-merror:0.216801\n",
      "[149]\teval-merror:0.216801\n",
      "[150]\teval-merror:0.216801\n",
      "[151]\teval-merror:0.216801\n",
      "[152]\teval-merror:0.216801\n",
      "[153]\teval-merror:0.216771\n",
      "[154]\teval-merror:0.216711\n",
      "[155]\teval-merror:0.216741\n",
      "[156]\teval-merror:0.216801\n",
      "[157]\teval-merror:0.216801\n",
      "[158]\teval-merror:0.216771\n",
      "[159]\teval-merror:0.216771\n",
      "[160]\teval-merror:0.216741\n",
      "[161]\teval-merror:0.216771\n",
      "[162]\teval-merror:0.216741\n",
      "[163]\teval-merror:0.216711\n",
      "[164]\teval-merror:0.216711\n",
      "[165]\teval-merror:0.216621\n",
      "[166]\teval-merror:0.216621\n",
      "[167]\teval-merror:0.216621\n",
      "[168]\teval-merror:0.216621\n",
      "[169]\teval-merror:0.216681\n",
      "[170]\teval-merror:0.216651\n",
      "[171]\teval-merror:0.216651\n",
      "[172]\teval-merror:0.216711\n",
      "[173]\teval-merror:0.216651\n",
      "[174]\teval-merror:0.216681\n",
      "[175]\teval-merror:0.216711\n",
      "[176]\teval-merror:0.216741\n",
      "[177]\teval-merror:0.216711\n",
      "[178]\teval-merror:0.216711\n",
      "[179]\teval-merror:0.216801\n",
      "[180]\teval-merror:0.216831\n",
      "[181]\teval-merror:0.216801\n",
      "[182]\teval-merror:0.216771\n",
      "[183]\teval-merror:0.216741\n",
      "[184]\teval-merror:0.216801\n",
      "[185]\teval-merror:0.216741\n",
      "[186]\teval-merror:0.216771\n",
      "[187]\teval-merror:0.216861\n",
      "[188]\teval-merror:0.216861\n",
      "[189]\teval-merror:0.216831\n",
      "[190]\teval-merror:0.216861\n",
      "[191]\teval-merror:0.216801\n",
      "[192]\teval-merror:0.216861\n",
      "[193]\teval-merror:0.216741\n",
      "[194]\teval-merror:0.216771\n",
      "[195]\teval-merror:0.216831\n",
      "[196]\teval-merror:0.216861\n",
      "[197]\teval-merror:0.216891\n",
      "[198]\teval-merror:0.216981\n",
      "[199]\teval-merror:0.216981\n",
      "[200]\teval-merror:0.216951\n",
      "[201]\teval-merror:0.216861\n",
      "[202]\teval-merror:0.216831\n",
      "[203]\teval-merror:0.216861\n",
      "[204]\teval-merror:0.216951\n",
      "[205]\teval-merror:0.216921\n",
      "[206]\teval-merror:0.216921\n",
      "[207]\teval-merror:0.216921\n",
      "[208]\teval-merror:0.216981\n",
      "[209]\teval-merror:0.216981\n",
      "[210]\teval-merror:0.216921\n",
      "[211]\teval-merror:0.216891\n",
      "[212]\teval-merror:0.216921\n",
      "[213]\teval-merror:0.216921\n",
      "[214]\teval-merror:0.216921\n",
      "[215]\teval-merror:0.216981\n",
      "[216]\teval-merror:0.216921\n",
      "Stopping. Best iteration:\n",
      "[116]\teval-merror:0.216321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold = 7\n",
    "skf = StratifiedKFold(n_splits=kfold, shuffle=True, random_state=42)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    submission = pd.DataFrame()\n",
    "    submission['UniqueID'] = te[\"UniqueID\"].values\n",
    "    submission['surface' + str(i+1)] = \"\"\n",
    "    \n",
    "    print('[Fold %d/%d]' % (i + 1, kfold))\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    \n",
    "    preds, model = runXGB(X_train, y_train, X_valid, y_valid, test)\n",
    "    \n",
    "    submission['loan_default' + str(i+1)] = preds\n",
    "    \n",
    "    submission.to_csv('submission_' + str(i+1) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission1 = pd.read_csv('submission_1.csv')\n",
    "submission2 = pd.read_csv('submission_2.csv')\n",
    "submission3 = pd.read_csv('submission_3.csv')\n",
    "submission4 = pd.read_csv('submission_4.csv')\n",
    "submission5 = pd.read_csv('submission_5.csv')\n",
    "submission6 = pd.read_csv('submission_6.csv')\n",
    "submission7 = pd.read_csv('submission_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "submissions = [submission1,submission2,submission3,submission4,submission5,submission6,submission7]\n",
    "submission_final = reduce(lambda left,right: pd.merge(left,right,on='UniqueID'), submissions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_final = pd.DataFrame(submission_final.mode(axis='columns'))\n",
    "submission_final = pd.DataFrame(submission_final[submission_final.columns[0]])\n",
    "submission_final.columns = ['loan_default']\n",
    "submission_final['loan_default'] = submission_final['loan_default'].astype('int')\n",
    "submission_final['loan_default'] = submission_final['loan_default']\n",
    "submission_final['loan_default'] = te.index.values\n",
    "submission_final.to_csv('submission_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>disbursed_amount</th>\n",
       "      <th>asset_cost</th>\n",
       "      <th>ltv</th>\n",
       "      <th>branch_id</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>manufacturer_id</th>\n",
       "      <th>Current_pincode_ID</th>\n",
       "      <th>Date.of.Birth</th>\n",
       "      <th>Employment.Type</th>\n",
       "      <th>...</th>\n",
       "      <th>SEC.CURRENT.BALANCE</th>\n",
       "      <th>SEC.SANCTIONED.AMOUNT</th>\n",
       "      <th>SEC.DISBURSED.AMOUNT</th>\n",
       "      <th>PRIMARY.INSTAL.AMT</th>\n",
       "      <th>SEC.INSTAL.AMT</th>\n",
       "      <th>NEW.ACCTS.IN.LAST.SIX.MONTHS</th>\n",
       "      <th>DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS</th>\n",
       "      <th>AVERAGE.ACCT.AGE</th>\n",
       "      <th>CREDIT.HISTORY.LENGTH</th>\n",
       "      <th>NO.OF_INQUIRIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>655269</td>\n",
       "      <td>53478</td>\n",
       "      <td>63558</td>\n",
       "      <td>86.54</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1497</td>\n",
       "      <td>01-01-74</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>723482</td>\n",
       "      <td>55513</td>\n",
       "      <td>63163</td>\n",
       "      <td>89.45</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1497</td>\n",
       "      <td>20-05-85</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 8mon</td>\n",
       "      <td>1yrs 0mon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>758529</td>\n",
       "      <td>65282</td>\n",
       "      <td>84320</td>\n",
       "      <td>79.93</td>\n",
       "      <td>78</td>\n",
       "      <td>23135</td>\n",
       "      <td>86</td>\n",
       "      <td>2071</td>\n",
       "      <td>14-10-95</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>763449</td>\n",
       "      <td>46905</td>\n",
       "      <td>63896</td>\n",
       "      <td>76.58</td>\n",
       "      <td>78</td>\n",
       "      <td>17014</td>\n",
       "      <td>45</td>\n",
       "      <td>2070</td>\n",
       "      <td>01-06-73</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2yrs 5mon</td>\n",
       "      <td>2yrs 5mon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>708663</td>\n",
       "      <td>51428</td>\n",
       "      <td>63896</td>\n",
       "      <td>86.08</td>\n",
       "      <td>78</td>\n",
       "      <td>17014</td>\n",
       "      <td>45</td>\n",
       "      <td>2069</td>\n",
       "      <td>01-06-72</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UniqueID  disbursed_amount  asset_cost    ltv  branch_id  supplier_id  \\\n",
       "0    655269             53478       63558  86.54         67        22807   \n",
       "1    723482             55513       63163  89.45         67        22807   \n",
       "2    758529             65282       84320  79.93         78        23135   \n",
       "3    763449             46905       63896  76.58         78        17014   \n",
       "4    708663             51428       63896  86.08         78        17014   \n",
       "\n",
       "   manufacturer_id  Current_pincode_ID Date.of.Birth Employment.Type  \\\n",
       "0               45                1497      01-01-74        Salaried   \n",
       "1               45                1497      20-05-85   Self employed   \n",
       "2               86                2071      14-10-95        Salaried   \n",
       "3               45                2070      01-06-73   Self employed   \n",
       "4               45                2069      01-06-72        Salaried   \n",
       "\n",
       "        ...        SEC.CURRENT.BALANCE  SEC.SANCTIONED.AMOUNT  \\\n",
       "0       ...                          0                      0   \n",
       "1       ...                          0                      0   \n",
       "2       ...                          0                      0   \n",
       "3       ...                          0                      0   \n",
       "4       ...                          0                      0   \n",
       "\n",
       "   SEC.DISBURSED.AMOUNT  PRIMARY.INSTAL.AMT  SEC.INSTAL.AMT  \\\n",
       "0                     0                   0               0   \n",
       "1                     0                5605               0   \n",
       "2                     0                   0               0   \n",
       "3                     0                   0               0   \n",
       "4                     0                   0               0   \n",
       "\n",
       "   NEW.ACCTS.IN.LAST.SIX.MONTHS  DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS  \\\n",
       "0                             0                                    0   \n",
       "1                             1                                    0   \n",
       "2                             0                                    0   \n",
       "3                             0                                    0   \n",
       "4                             0                                    0   \n",
       "\n",
       "   AVERAGE.ACCT.AGE  CREDIT.HISTORY.LENGTH  NO.OF_INQUIRIES  \n",
       "0         0yrs 0mon              0yrs 0mon                0  \n",
       "1         0yrs 8mon              1yrs 0mon                1  \n",
       "2         0yrs 0mon              0yrs 0mon                0  \n",
       "3         2yrs 5mon              2yrs 5mon                0  \n",
       "4         0yrs 0mon              0yrs 0mon                0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import ensemble\n",
    "rf = ensemble.RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    #criterion=\"gini\",\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=1,\n",
    "    random_state=None,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    class_weight=None,\n",
    ")\n",
    "rf.fit(train_data, target)\n",
    "y_pred = rf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = pd.DataFrame({'UniqueID':submission['UniqueID'],'loan_default':y_pred})\n",
    "final_result.to_csv('6stSolution.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 features their importance value is less then 0.0025\n"
     ]
    }
   ],
   "source": [
    "less_important_features = feature_importances.loc[feature_importances['importance'] < 0.0025]\n",
    "print('There are {0} features their importance value is less then 0.0025'.format(less_important_features.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data.drop(columns = ['MobileNo_Avl_Flag', 'Passport_flag', 'SEC.NO.OF.ACCTS',\n",
    "       'SEC.ACTIVE.ACCTS', 'SEC.OVERDUE.ACCTS', 'SEC.CURRENT.BALANCE',\n",
    "       'SEC.SANCTIONED.AMOUNT', 'SEC.DISBURSED.AMOUNT', 'SEC.INSTAL.AMT',\n",
    "       'Disbursal_Year'], axis = 1)\n",
    "test = test_data.drop(columns = ['MobileNo_Avl_Flag', 'Passport_flag', 'SEC.NO.OF.ACCTS',\n",
    "       'SEC.ACTIVE.ACCTS', 'SEC.OVERDUE.ACCTS', 'SEC.CURRENT.BALANCE',\n",
    "       'SEC.SANCTIONED.AMOUNT', 'SEC.DISBURSED.AMOUNT', 'SEC.INSTAL.AMT',\n",
    "       'Disbursal_Year'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score 0.7751700438245912\n"
     ]
    }
   ],
   "source": [
    "print('Average score', score / folds.n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[177863,  47740],\n",
       "       [  4680,   2871]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(measured,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,24,'Predicted label')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x191a2fa3198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(12,5))\n",
    "sns.heatmap(pd.DataFrame(confusion_matrix(measured,target)),\n",
    "            ax = ax,\n",
    "            cmap = 'coolwarm',\n",
    "            annot = True,\n",
    "            fmt = '.2f',\n",
    "            linewidths = 0.05)\n",
    "fig.subplots_adjust(top=0.93)\n",
    "fig.suptitle('Confusion matrix, Actual vs Predicted label Correlation Heatmap', \n",
    "              fontsize=14, \n",
    "              fontweight='bold')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_], axis = 0)\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>disbursed_amount</th>\n",
       "      <td>0.121752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asset_cost</th>\n",
       "      <td>0.117811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ltv</th>\n",
       "      <td>0.128222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>branch_id</th>\n",
       "      <td>0.042462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supplier_id</th>\n",
       "      <td>0.080403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manufacturer_id</th>\n",
       "      <td>0.024365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Current_pincode_ID</th>\n",
       "      <td>0.112563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State_ID</th>\n",
       "      <td>0.025609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employee_code_ID</th>\n",
       "      <td>0.092280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MobileNo_Avl_Flag</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aadhar_flag</th>\n",
       "      <td>0.005880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAN_flag</th>\n",
       "      <td>0.006902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VoterID_flag</th>\n",
       "      <td>0.006062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Driving_flag</th>\n",
       "      <td>0.003078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passport_flag</th>\n",
       "      <td>0.000445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERFORM_CNS.SCORE</th>\n",
       "      <td>0.036616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRI.NO.OF.ACCTS</th>\n",
       "      <td>0.021912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRI.ACTIVE.ACCTS</th>\n",
       "      <td>0.011725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRI.OVERDUE.ACCTS</th>\n",
       "      <td>0.006604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRI.CURRENT.BALANCE</th>\n",
       "      <td>0.030259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importance\n",
       "disbursed_amount       0.121752\n",
       "asset_cost             0.117811\n",
       "ltv                    0.128222\n",
       "branch_id              0.042462\n",
       "supplier_id            0.080403\n",
       "manufacturer_id        0.024365\n",
       "Current_pincode_ID     0.112563\n",
       "State_ID               0.025609\n",
       "Employee_code_ID       0.092280\n",
       "MobileNo_Avl_Flag      0.000000\n",
       "Aadhar_flag            0.005880\n",
       "PAN_flag               0.006902\n",
       "VoterID_flag           0.006062\n",
       "Driving_flag           0.003078\n",
       "Passport_flag          0.000445\n",
       "PERFORM_CNS.SCORE      0.036616\n",
       "PRI.NO.OF.ACCTS        0.021912\n",
       "PRI.ACTIVE.ACCTS       0.011725\n",
       "PRI.OVERDUE.ACCTS      0.006604\n",
       "PRI.CURRENT.BALANCE    0.030259"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(importances, index = train_data.columns, columns = ['importance'])\n",
    "feature_importances.sort_values('importance', ascending = False)\n",
    "feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 features their importance value is less then 0.0025\n"
     ]
    }
   ],
   "source": [
    "less_important_features = feature_importances.loc[feature_importances['importance'] < 0.0025]\n",
    "print('There are {0} features their importance value is less then 0.0025'.format(less_important_features.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove less important features from train and test set.\n",
    "for i, col in enumerate(less_important_features.index):\n",
    "    data = train_data.drop(columns = [col], axis = 1)\n",
    "    test = test_data.drop(columns = [col], axis = 1)\n",
    "    \n",
    "data.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission['surface'] = le.inverse_transform(predicted.argmax(axis=1))\n",
    "submission.to_csv('rs_surface_submission6.csv', index=False)\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-c0015fbb66a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission_24jSKY6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = pd.DataFrame({'UniqueID':submission['UniqueID'],'loan_default':predicted})\n",
    "final_result.to_csv('6stSolution.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(\n",
    "    C=5,\n",
    "    kernel=\"rbf\",\n",
    "    degree=3,\n",
    "    gamma=\"auto\",\n",
    "    coef0=0.0,\n",
    "    shrinking=True,\n",
    "    probability=False,\n",
    "    tol=0.001,\n",
    "    cache_size=200,\n",
    "    class_weight=None,\n",
    "    verbose=False,\n",
    "    max_iter=-1,\n",
    "    decision_function_shape=\"ovr\",\n",
    "    random_state=None,\n",
    ")\n",
    "model = svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
